{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = Path(\"/Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/\")\n",
    "data_path = HOME_DIR / 'public-data' / 'open-australian-legal-qa' / 'qa.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry 1: {'question': \"In the case of Nasr v NRMA Insurance [2006] NSWSC 1018, why was the plaintiff's appeal lodged out of time?\", 'answer': \"In Nasr v NRMA Insurance [2006] NSWSC 1018, the plaintiff's appeal was lodged out of time because the summons was filed on 8 June 2006, seven months after the decision of the Local Court was made on 4 October 2005. No explanation was provided for this delay.\", 'text': \"Question: In the case of Nasr v NRMA Insurance [2006] NSWSC 1018, why was the plaintiff's appeal lodged out of time?\\nAnswer: In Nasr v NRMA Insurance [2006] NSWSC 1018, the plaintiff's appeal was lodged out of time because the summons was filed on 8 June 2006, seven months after the decision of the Local Court was made on 4 October 2005. No explanation was provided for this delay.\", 'prompt': \"# Snippet\\nThe snippet from an Australian legal document from which you must synthesise a question and answer is provided below.\\n<document_metadata>\\n<document_title>Nasr v NRMA Insurance [2006] NSWSC 1018</document_title>\\n<document_jurisdiction>New South Wales</document_jurisdiction>\\n<document_type>Decision</document_type>\\n</document_metadata>\\n<snippet>\\n 3 The plaintiff claims that he was overseas when the Local Court struck out his case against the NRMA and they (the NRMA) rejected payment of his claim for his car after it was burnt on 6 July 2004. There are no grounds of appeal in his summons but it may be that he could have submitted that he was denied procedural fairness or natural justice. 4 This appeal has been lodged out of time. The decision of the Local Court was made on 4 October 2005. The summons was filed on 8 June 2006, some seven months out of time. No explanation has been provided for this delay. In these circumstances this Court cannot grant an extension of time in which to lodge this appeal. The Local Court proceedings 5 The Local Court file was not before this Court. There are four letters from the Local Court in evidence. The statement of claim is not before this Court. However, it seems that Mr Nasr sued the NRMA because it denied to pay a claim he made pursuant to his motor vehicle insurance policy and he was seeking damages. Doing the best I can, it appears that Mr Nasr sought and was granted a number of adjournments while he was overseas in China. \\n</snippet>\\n\\n# Format\\nYou must format your response as follows:\\n<format>\\n# Question\\n{A question related to the snippet, or a topic discussed therein.}\\n\\n# Answer\\n{The answer to the question, extracted from the snippet.}\\n</format>\\n\\n# Instructions\\nYou must act as a question-and-answer synthesiser that takes a snippet from an Australian legal document and synthesises a question related to the snippet, or a topic discussed therein, and an answer to that question, extracted from the snippet.\\n\\nYour question must be decontextualised and standalone from the snippet. If the question pertains to a particular jurisdiction or document, it must state that explicitly (eg, 'In Victoria, is it lawful for ...?', 'What did the Court decide in Mabo v Queensland (No 2) [1992] HCA 23?', etc...).\\n\\nYour answer must also be decontextualised and standalone from the snippet. It must reference the document from which it came (eg, 'Under the Crimes Act 1958 (Vic), ...', 'In Mabo v Queensland (No 2) [1992] HCA 23, the Court decided ...', etc...), not the snippet itself. It must be capable of being understood on its own and without reference to the snippet or its source document.\\n\\nWhen referring to a document (eg, the Crimes Act) or a part thereof (eg, Paragraph 1), or to a person (eg, the Minister), organisation (eg, the Department) or concept (eg, the rule of law), you must refer to it by its full name (eg, the Crimes Act 1958 (Vic) instead of the Crimes Act, Paragraph 1 of ABC v XYZ instead of Paragraph 1, the Commonwealth Minister for Finance instead of the Minister).\\n\\nIf it is not possible to synthesise a question and answer from the snippet, you must respond with `<!no_qa!>`. Otherwise, your response must conform to the provided format.\", 'source': {'version_id': 'nsw_caselaw:549fc6183004262463bb648a', 'type': 'decision', 'jurisdiction': 'new_south_wales', 'source': 'nsw_caselaw', 'citation': 'Nasr v NRMA Insurance [2006] NSWSC 1018', 'url': 'https://www.caselaw.nsw.gov.au/decision/549fc6183004262463bb648a', 'text': ' 3 The plaintiff claims that he was overseas when the Local Court struck out his case against the NRMA and they (the NRMA) rejected payment of his claim for his car after it was burnt on 6 July 2004. There are no grounds of appeal in his summons but it may be that he could have submitted that he was denied procedural fairness or natural justice. 4 This appeal has been lodged out of time. The decision of the Local Court was made on 4 October 2005. The summons was filed on 8 June 2006, some seven months out of time. No explanation has been provided for this delay. In these circumstances this Court cannot grant an extension of time in which to lodge this appeal. The Local Court proceedings 5 The Local Court file was not before this Court. There are four letters from the Local Court in evidence. The statement of claim is not before this Court. However, it seems that Mr Nasr sued the NRMA because it denied to pay a claim he made pursuant to his motor vehicle insurance policy and he was seeking damages. Doing the best I can, it appears that Mr Nasr sought and was granted a number of adjournments while he was overseas in China. '}}\n",
      "Entry 2: {'question': 'In the case of R v NGUYEN [2001] NSWCCA 334, what was the relationship between the Appellant and Mr Nguyen, and what activities of Mr Nguyen did the Appellant testify about?', 'answer': \"In the case of R v NGUYEN [2001] NSWCCA 334, the Appellant testified that Mr Nguyen was her cousin and that she had allowed him to live in her flat for about 4 or 5 days. She stated that she had heard that Mr Nguyen was selling heroin and that she had seen him hand over a small foil to a third person, an event that made her feel surprised, upset, and angry. Despite her protests, Mr Nguyen allegedly continued to sell heroin from the flat. The Appellant also mentioned seeing other customers in the flat and a friend of Mr Nguyen's cutting foil in the lounge-room. Despite her complaints to her boyfriend and an aunt, she took no further steps to prevent these activities, citing reasons such as their close familial relationship and her reluctance to involve the police.\", 'text': \"Question: In the case of R v NGUYEN [2001] NSWCCA 334, what was the relationship between the Appellant and Mr Nguyen, and what activities of Mr Nguyen did the Appellant testify about?\\nAnswer: In the case of R v NGUYEN [2001] NSWCCA 334, the Appellant testified that Mr Nguyen was her cousin and that she had allowed him to live in her flat for about 4 or 5 days. She stated that she had heard that Mr Nguyen was selling heroin and that she had seen him hand over a small foil to a third person, an event that made her feel surprised, upset, and angry. Despite her protests, Mr Nguyen allegedly continued to sell heroin from the flat. The Appellant also mentioned seeing other customers in the flat and a friend of Mr Nguyen's cutting foil in the lounge-room. Despite her complaints to her boyfriend and an aunt, she took no further steps to prevent these activities, citing reasons such as their close familial relationship and her reluctance to involve the police.\", 'prompt': \"# Snippet\\nThe snippet from an Australian legal document from which you must synthesise a question and answer is provided below.\\n<document_metadata>\\n<document_title>R v NGUYEN [2001] NSWCCA 334</document_title>\\n<document_jurisdiction>New South Wales</document_jurisdiction>\\n<document_type>Decision</document_type>\\n</document_metadata>\\n<snippet>\\n 29 The Appellant also gave evidence that she had permitted Mr Nguyen to live in the flat for about 4 or 5 days before the 6th November, because he was her cousin and had nowhere else at that time to live. According to the Appellant, he and sometimes his girlfriend occupied the second bedroom and some others who moved in at the same time slept in the lounge-room. The Appellant said that before Mr Nguyen moved in she had heard that he was selling heroin. On the first day he was with her she saw him hand over a small foil to a third person, an event she said which made her feel, “surprised, upset and angry”. She protested at the event and told Mr Nguyen that if he continued to do that he would have to move out. Nevertheless, according to the Appellant, Mr Nguyen continued to sell heroin and she argued with him nearly every day. Asked how many times she saw other customers in the flat, the Appellant said “Once, twice or three times, I’m not so sure” and “maybe one customer or two customers a day”. A friend of Mr Nguyen’s also cut foil in the lounge-room. 30 According to the Appellant, she complained about Mr Nguyen’s activities to her boyfriend and an aunt, but she took no further steps to prevent those activities. She gave a variety of reasons for this. They included:- He was her eldest cousin and they had been very close. He told her that she should not contact the police. She didn’t want him to go to gaol because he was family and they “were like brothers and sisters”. \\n</snippet>\\n\\n# Format\\nYou must format your response as follows:\\n<format>\\n# Question\\n{A question related to the snippet, or a topic discussed therein.}\\n\\n# Answer\\n{The answer to the question, extracted from the snippet.}\\n</format>\\n\\n# Instructions\\nYou must act as a question-and-answer synthesiser that takes a snippet from an Australian legal document and synthesises a question related to the snippet, or a topic discussed therein, and an answer to that question, extracted from the snippet.\\n\\nYour question must be decontextualised and standalone from the snippet. If the question pertains to a particular jurisdiction or document, it must state that explicitly (eg, 'In Victoria, is it lawful for ...?', 'What did the Court decide in Mabo v Queensland (No 2) [1992] HCA 23?', etc...).\\n\\nYour answer must also be decontextualised and standalone from the snippet. It must reference the document from which it came (eg, 'Under the Crimes Act 1958 (Vic), ...', 'In Mabo v Queensland (No 2) [1992] HCA 23, the Court decided ...', etc...), not the snippet itself. It must be capable of being understood on its own and without reference to the snippet or its source document.\\n\\nWhen referring to a document (eg, the Crimes Act) or a part thereof (eg, Paragraph 1), or to a person (eg, the Minister), organisation (eg, the Department) or concept (eg, the rule of law), you must refer to it by its full name (eg, the Crimes Act 1958 (Vic) instead of the Crimes Act, Paragraph 1 of ABC v XYZ instead of Paragraph 1, the Commonwealth Minister for Finance instead of the Minister).\\n\\nIf it is not possible to synthesise a question and answer from the snippet, you must respond with `<!no_qa!>`. Otherwise, your response must conform to the provided format.\", 'source': {'version_id': 'nsw_caselaw:549f9fcc3004262463b2ba04', 'type': 'decision', 'jurisdiction': 'new_south_wales', 'source': 'nsw_caselaw', 'citation': 'R v NGUYEN [2001] NSWCCA 334', 'url': 'https://www.caselaw.nsw.gov.au/decision/549f9fcc3004262463b2ba04', 'text': ' 29 The Appellant also gave evidence that she had permitted Mr Nguyen to live in the flat for about 4 or 5 days before the 6th November, because he was her cousin and had nowhere else at that time to live. According to the Appellant, he and sometimes his girlfriend occupied the second bedroom and some others who moved in at the same time slept in the lounge-room. The Appellant said that before Mr Nguyen moved in she had heard that he was selling heroin. On the first day he was with her she saw him hand over a small foil to a third person, an event she said which made her feel, “surprised, upset and angry”. She protested at the event and told Mr Nguyen that if he continued to do that he would have to move out. Nevertheless, according to the Appellant, Mr Nguyen continued to sell heroin and she argued with him nearly every day. Asked how many times she saw other customers in the flat, the Appellant said “Once, twice or three times, I’m not so sure” and “maybe one customer or two customers a day”. A friend of Mr Nguyen’s also cut foil in the lounge-room. 30 According to the Appellant, she complained about Mr Nguyen’s activities to her boyfriend and an aunt, but she took no further steps to prevent those activities. She gave a variety of reasons for this. They included:- He was her eldest cousin and they had been very close. He told her that she should not contact the police. She didn’t want him to go to gaol because he was family and they “were like brothers and sisters”. '}}\n",
      "Entry 3: {'question': \"In the case of Moore v Scenic Tours Pty Ltd [2015] NSWSC 237, what was the court's decision regarding the motion to restrain a firm from acting?\", 'answer': 'In the case of Moore v Scenic Tours Pty Ltd [2015] NSWSC 237, the court decided to dismiss the motion to restrain a firm from acting. The court found that the plaintiff was entitled to a solicitor of their choice and it was not in the interest of justice to deprive the plaintiff of their choice of solicitor.', 'text': \"Question: In the case of Moore v Scenic Tours Pty Ltd [2015] NSWSC 237, what was the court's decision regarding the motion to restrain a firm from acting?\\nAnswer: In the case of Moore v Scenic Tours Pty Ltd [2015] NSWSC 237, the court decided to dismiss the motion to restrain a firm from acting. The court found that the plaintiff was entitled to a solicitor of their choice and it was not in the interest of justice to deprive the plaintiff of their choice of solicitor.\", 'prompt': \"# Snippet\\nThe snippet from an Australian legal document from which you must synthesise a question and answer is provided below.\\n<document_metadata>\\n<document_title>Moore v Scenic Tours Pty Ltd [2015] NSWSC 237</document_title>\\n<document_jurisdiction>New South Wales</document_jurisdiction>\\n<document_type>Decision</document_type>\\n</document_metadata>\\n<snippet>\\nMedium Neutral Citation: Moore v Scenic Tours Pty Ltd [2015] NSWSC 237 Hearing dates: 27 February 2015 Date of orders: 20 March 2015 Decision date: 20 March 2015 Jurisdiction: Common Law Before: Garling J Decision: (a)Amended Notice of Motion dated 20 February 2015 is dismissed. (b)Defendant to pay the plaintiff’s costs. Catchwords: PRACTICE AND PROCEDURE – civil – representative proceedings – whether court should exercise jurisdiction to restrain a firm from acting – ultimate controller and majority owner of firm representing plaintiff falls within group members in proceedings – son of ultimate controller of firm is sole director of litigation funder – whether arrangement designed to circumvent prohibition on contingency fees – litigation funder company of limited capital – whether litigation funder has sufficient capital to meet adverse costs order – plaintiff consents to firm continuing to act – plaintiff entitled to a solicitor of their choice – not in interest of justice to deprive plaintiff of their choice of solicitor – motion to restrain firm from acting dismissed Legislation Cited: Civil Procedure Act 2005 Corporations Regulation 2001 Family Law Act 1975 (Cth) Legal Profession Act 2004 \\n</snippet>\\n\\n# Format\\nYou must format your response as follows:\\n<format>\\n# Question\\n{A question related to the snippet, or a topic discussed therein.}\\n\\n# Answer\\n{The answer to the question, extracted from the snippet.}\\n</format>\\n\\n# Instructions\\nYou must act as a question-and-answer synthesiser that takes a snippet from an Australian legal document and synthesises a question related to the snippet, or a topic discussed therein, and an answer to that question, extracted from the snippet.\\n\\nYour question must be decontextualised and standalone from the snippet. If the question pertains to a particular jurisdiction or document, it must state that explicitly (eg, 'In Victoria, is it lawful for ...?', 'What did the Court decide in Mabo v Queensland (No 2) [1992] HCA 23?', etc...).\\n\\nYour answer must also be decontextualised and standalone from the snippet. It must reference the document from which it came (eg, 'Under the Crimes Act 1958 (Vic), ...', 'In Mabo v Queensland (No 2) [1992] HCA 23, the Court decided ...', etc...), not the snippet itself. It must be capable of being understood on its own and without reference to the snippet or its source document.\\n\\nWhen referring to a document (eg, the Crimes Act) or a part thereof (eg, Paragraph 1), or to a person (eg, the Minister), organisation (eg, the Department) or concept (eg, the rule of law), you must refer to it by its full name (eg, the Crimes Act 1958 (Vic) instead of the Crimes Act, Paragraph 1 of ABC v XYZ instead of Paragraph 1, the Commonwealth Minister for Finance instead of the Minister).\\n\\nIf it is not possible to synthesise a question and answer from the snippet, you must respond with `<!no_qa!>`. Otherwise, your response must conform to the provided format.\", 'source': {'version_id': 'nsw_caselaw:55076e09e4b0d39cca7e1f98', 'type': 'decision', 'jurisdiction': 'new_south_wales', 'source': 'nsw_caselaw', 'citation': 'Moore v Scenic Tours Pty Ltd [2015] NSWSC 237', 'url': 'https://www.caselaw.nsw.gov.au/decision/55076e09e4b0d39cca7e1f98', 'text': 'Medium Neutral Citation: Moore v Scenic Tours Pty Ltd [2015] NSWSC 237 Hearing dates: 27 February 2015 Date of orders: 20 March 2015 Decision date: 20 March 2015 Jurisdiction: Common Law Before: Garling J Decision: (a)Amended Notice of Motion dated 20 February 2015 is dismissed. (b)Defendant to pay the plaintiff’s costs. Catchwords: PRACTICE AND PROCEDURE – civil – representative proceedings – whether court should exercise jurisdiction to restrain a firm from acting – ultimate controller and majority owner of firm representing plaintiff falls within group members in proceedings – son of ultimate controller of firm is sole director of litigation funder – whether arrangement designed to circumvent prohibition on contingency fees – litigation funder company of limited capital – whether litigation funder has sufficient capital to meet adverse costs order – plaintiff consents to firm continuing to act – plaintiff entitled to a solicitor of their choice – not in interest of justice to deprive plaintiff of their choice of solicitor – motion to restrain firm from acting dismissed Legislation Cited: Civil Procedure Act 2005 Corporations Regulation 2001 Family Law Act 1975 (Cth) Legal Profession Act 2004 '}}\n",
      "Entry 4: {'question': 'What were the circumstances and outcomes of the case Inspector Phillip Estreich v Hannas Civil Engineering Pty Ltd and Afram Hanna [2009] NSWIRComm 168 in New South Wales?', 'answer': \"In the case of Inspector Phillip Estreich v Hannas Civil Engineering Pty Ltd and Afram Hanna [2009] NSWIRComm 168, the defendants were charged under the Occupational Health and Safety Act 2000 for a serious breach of safety. The incident involved a worker who was injured while cutting an orange conduit that was assumed to hold no energised cable or services, but in fact held an 11,000 volt electric cable. The work was not performed in accordance with the company's documented safety system and the risk was foreseeable. Both the company and the contracted supervisor pleaded guilty. The company had a prior record, while the supervisor did not. The company showed contrition, entered an early plea, and took numerous remedial steps after the accident. The supervisor changed his original plea, but the circumstances warranted a significant discount. Penalties were imposed considering the company's good industrial record, good corporate citizenship, and co-operation with the WorkCover Authority.\", 'text': \"Question: What were the circumstances and outcomes of the case Inspector Phillip Estreich v Hannas Civil Engineering Pty Ltd and Afram Hanna [2009] NSWIRComm 168 in New South Wales?\\nAnswer: In the case of Inspector Phillip Estreich v Hannas Civil Engineering Pty Ltd and Afram Hanna [2009] NSWIRComm 168, the defendants were charged under the Occupational Health and Safety Act 2000 for a serious breach of safety. The incident involved a worker who was injured while cutting an orange conduit that was assumed to hold no energised cable or services, but in fact held an 11,000 volt electric cable. The work was not performed in accordance with the company's documented safety system and the risk was foreseeable. Both the company and the contracted supervisor pleaded guilty. The company had a prior record, while the supervisor did not. The company showed contrition, entered an early plea, and took numerous remedial steps after the accident. The supervisor changed his original plea, but the circumstances warranted a significant discount. Penalties were imposed considering the company's good industrial record, good corporate citizenship, and co-operation with the WorkCover Authority.\", 'prompt': \"# Snippet\\nThe snippet from an Australian legal document from which you must synthesise a question and answer is provided below.\\n<document_metadata>\\n<document_title>Inspector Phillip Estreich v Hannas Civil Engineering Pty Ltd and Afram Hanna [2009] NSWIRComm 168</document_title>\\n<document_jurisdiction>New South Wales</document_jurisdiction>\\n<document_type>Decision</document_type>\\n</document_metadata>\\n<snippet>\\n CITATION: Inspector Phillip Estreich v Hannas Civil Engineering Pty Ltd and Afram Hanna [2009] NSWIRComm 168 Inspector Phillip Estreich (Prosecutor) PARTIES: Hannas Civil Engineering Pty Ltd (Defendant in IRC 2009/179) Afram Hanna (Defendant in 2009/206) FILE NUMBER(S): IRC 179 and 206 of 2009 CORAM: Haylen J CATCHWORDS: OCCUPATIONAL HEALTH AND SAFETY ACT 2000 - s 8(2), s 10(1) - pleas of guilty - company and contracted supervisor - orange conduit exposed - conduit assumed to hold no energised cable or services - one cable holds 11,000 volt electric cable - worker injured whilst cutting conduit - serious injuries received - work not performed in accordance with company's documented safety system - simple steps laid down to ascertain whether services in area - risk foreseeable - serious breach - general and specific deterrence - subjective factors considered - company had prior record - supervisor had no prior record - contrition - company enters early plea - supervisor changes original plea but circumstances warrant significant discount - good industrial record and good corporate citizenship established - co-operation with WorkCover Authority - numerous remedial steps taken after accident - s 6 Fines Act consideration - penalties imposed \\n</snippet>\\n\\n# Format\\nYou must format your response as follows:\\n<format>\\n# Question\\n{A question related to the snippet, or a topic discussed therein.}\\n\\n# Answer\\n{The answer to the question, extracted from the snippet.}\\n</format>\\n\\n# Instructions\\nYou must act as a question-and-answer synthesiser that takes a snippet from an Australian legal document and synthesises a question related to the snippet, or a topic discussed therein, and an answer to that question, extracted from the snippet.\\n\\nYour question must be decontextualised and standalone from the snippet. If the question pertains to a particular jurisdiction or document, it must state that explicitly (eg, 'In Victoria, is it lawful for ...?', 'What did the Court decide in Mabo v Queensland (No 2) [1992] HCA 23?', etc...).\\n\\nYour answer must also be decontextualised and standalone from the snippet. It must reference the document from which it came (eg, 'Under the Crimes Act 1958 (Vic), ...', 'In Mabo v Queensland (No 2) [1992] HCA 23, the Court decided ...', etc...), not the snippet itself. It must be capable of being understood on its own and without reference to the snippet or its source document.\\n\\nWhen referring to a document (eg, the Crimes Act) or a part thereof (eg, Paragraph 1), or to a person (eg, the Minister), organisation (eg, the Department) or concept (eg, the rule of law), you must refer to it by its full name (eg, the Crimes Act 1958 (Vic) instead of the Crimes Act, Paragraph 1 of ABC v XYZ instead of Paragraph 1, the Commonwealth Minister for Finance instead of the Minister).\\n\\nIf it is not possible to synthesise a question and answer from the snippet, you must respond with `<!no_qa!>`. Otherwise, your response must conform to the provided format.\", 'source': {'version_id': 'nsw_caselaw:549f80003004262463aae15b', 'type': 'decision', 'jurisdiction': 'new_south_wales', 'source': 'nsw_caselaw', 'citation': 'Inspector Phillip Estreich v Hannas Civil Engineering Pty Ltd and Afram Hanna [2009] NSWIRComm 168', 'url': 'https://www.caselaw.nsw.gov.au/decision/549f80003004262463aae15b', 'text': \" CITATION: Inspector Phillip Estreich v Hannas Civil Engineering Pty Ltd and Afram Hanna [2009] NSWIRComm 168 Inspector Phillip Estreich (Prosecutor) PARTIES: Hannas Civil Engineering Pty Ltd (Defendant in IRC 2009/179) Afram Hanna (Defendant in 2009/206) FILE NUMBER(S): IRC 179 and 206 of 2009 CORAM: Haylen J CATCHWORDS: OCCUPATIONAL HEALTH AND SAFETY ACT 2000 - s 8(2), s 10(1) - pleas of guilty - company and contracted supervisor - orange conduit exposed - conduit assumed to hold no energised cable or services - one cable holds 11,000 volt electric cable - worker injured whilst cutting conduit - serious injuries received - work not performed in accordance with company's documented safety system - simple steps laid down to ascertain whether services in area - risk foreseeable - serious breach - general and specific deterrence - subjective factors considered - company had prior record - supervisor had no prior record - contrition - company enters early plea - supervisor changes original plea but circumstances warrant significant discount - good industrial record and good corporate citizenship established - co-operation with WorkCover Authority - numerous remedial steps taken after accident - s 6 Fines Act consideration - penalties imposed \"}}\n",
      "Entry 5: {'question': 'In the case of Ruddock v Vadarlis [2001] FCA 1329, what was the argument of the Commonwealth regarding the application of habeas corpus and how was it received?', 'answer': 'In Ruddock v Vadarlis [2001] FCA 1329, the Commonwealth argued that habeas corpus did not apply as the rescuees were not detained. They contended that for a detention to occur, the detainer must subject the detainee to a total restraint of movement, and that partial restraint or obstruction from going in a particular direction does not constitute detention. They further argued that the rescuees were only prevented from going to their preferred destination and were free to go elsewhere, thus not constituting detention. However, this argument was not accepted by the court, which disagreed with the suggestion that a \"total restraint of movement\" is necessary to constitute detention amenable to habeas corpus.', 'text': 'Question: In the case of Ruddock v Vadarlis [2001] FCA 1329, what was the argument of the Commonwealth regarding the application of habeas corpus and how was it received?\\nAnswer: In Ruddock v Vadarlis [2001] FCA 1329, the Commonwealth argued that habeas corpus did not apply as the rescuees were not detained. They contended that for a detention to occur, the detainer must subject the detainee to a total restraint of movement, and that partial restraint or obstruction from going in a particular direction does not constitute detention. They further argued that the rescuees were only prevented from going to their preferred destination and were free to go elsewhere, thus not constituting detention. However, this argument was not accepted by the court, which disagreed with the suggestion that a \"total restraint of movement\" is necessary to constitute detention amenable to habeas corpus.', 'prompt': '# Snippet\\nThe snippet from an Australian legal document from which you must synthesise a question and answer is provided below.\\n<document_metadata>\\n<document_title>Ruddock v Vadarlis [2001] FCA 1329</document_title>\\n<document_jurisdiction>Commonwealth</document_jurisdiction>\\n<document_type>Decision</document_type>\\n</document_metadata>\\n<snippet>\\n 206 It was submitted for the Commonwealth that habeas corpus did not lie as the rescuees were not detained. For a detention to take place the detainer must subject the detainee to a total restraint of movement. Partial restraint was to be distinguished from detention. To obstruct a person from going in a particular direction, it was argued, does not constitute detention. The rescuees were only prevented from going to their preferred destination. That limited restriction, it was submitted, did not constitute detention given that they were free to proceed to any other destination. It was contended for VCCL and Vadarlis that \"close custody\" is not necessary to attract the remedy of habeas corpus. In the alternative it was submitted that North J was correct to conclude, as a matter of fact, that the restraint upon the rescuees was total. I do not accept the argument for the Commonwealth insofar as it may be taken to suggest that a \"total restraint of movement\" is necessary to constitute detention amenable to habeas corpus.\\n</snippet>\\n\\n# Format\\nYou must format your response as follows:\\n<format>\\n# Question\\n{A question related to the snippet, or a topic discussed therein.}\\n\\n# Answer\\n{The answer to the question, extracted from the snippet.}\\n</format>\\n\\n# Instructions\\nYou must act as a question-and-answer synthesiser that takes a snippet from an Australian legal document and synthesises a question related to the snippet, or a topic discussed therein, and an answer to that question, extracted from the snippet.\\n\\nYour question must be decontextualised and standalone from the snippet. If the question pertains to a particular jurisdiction or document, it must state that explicitly (eg, \\'In Victoria, is it lawful for ...?\\', \\'What did the Court decide in Mabo v Queensland (No 2) [1992] HCA 23?\\', etc...).\\n\\nYour answer must also be decontextualised and standalone from the snippet. It must reference the document from which it came (eg, \\'Under the Crimes Act 1958 (Vic), ...\\', \\'In Mabo v Queensland (No 2) [1992] HCA 23, the Court decided ...\\', etc...), not the snippet itself. It must be capable of being understood on its own and without reference to the snippet or its source document.\\n\\nWhen referring to a document (eg, the Crimes Act) or a part thereof (eg, Paragraph 1), or to a person (eg, the Minister), organisation (eg, the Department) or concept (eg, the rule of law), you must refer to it by its full name (eg, the Crimes Act 1958 (Vic) instead of the Crimes Act, Paragraph 1 of ABC v XYZ instead of Paragraph 1, the Commonwealth Minister for Finance instead of the Minister).\\n\\nIf it is not possible to synthesise a question and answer from the snippet, you must respond with `<!no_qa!>`. Otherwise, your response must conform to the provided format.', 'source': {'version_id': 'federal_court_of_australia:fca/single/2001/2001fca1329', 'type': 'decision', 'jurisdiction': 'commonwealth', 'source': 'federal_court_of_australia', 'citation': 'Ruddock v Vadarlis [2001] FCA 1329', 'url': 'https://www.judgments.fedcourt.gov.au/judgments/Judgments/fca/single/2001/2001fca1329', 'text': ' 206 It was submitted for the Commonwealth that habeas corpus did not lie as the rescuees were not detained. For a detention to take place the detainer must subject the detainee to a total restraint of movement. Partial restraint was to be distinguished from detention. To obstruct a person from going in a particular direction, it was argued, does not constitute detention. The rescuees were only prevented from going to their preferred destination. That limited restriction, it was submitted, did not constitute detention given that they were free to proceed to any other destination. It was contended for VCCL and Vadarlis that \"close custody\" is not necessary to attract the remedy of habeas corpus. In the alternative it was submitted that North J was correct to conclude, as a matter of fact, that the restraint upon the rescuees was total. I do not accept the argument for the Commonwealth insofar as it may be taken to suggest that a \"total restraint of movement\" is necessary to constitute detention amenable to habeas corpus.'}}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "if data_path.exists():\n",
    "    with open(data_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "else:\n",
    "    print(f\"File not found: {data_path}\")\n",
    "\n",
    "for i, item in enumerate(data[:5]):\n",
    "    print(f\"Entry {i+1}: {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: In the case of Nasr v NRMA Insurance [2006] NSWSC 1018, why was the plaintiff's appeal lodged out of time?\n",
      "Question 2: In the case of R v NGUYEN [2001] NSWCCA 334, what was the relationship between the Appellant and Mr Nguyen, and what activities of Mr Nguyen did the Appellant testify about?\n",
      "Question 3: In the case of Moore v Scenic Tours Pty Ltd [2015] NSWSC 237, what was the court's decision regarding the motion to restrain a firm from acting?\n",
      "Question 4: What were the circumstances and outcomes of the case Inspector Phillip Estreich v Hannas Civil Engineering Pty Ltd and Afram Hanna [2009] NSWIRComm 168 in New South Wales?\n",
      "Question 5: In the case of Ruddock v Vadarlis [2001] FCA 1329, what was the argument of the Commonwealth regarding the application of habeas corpus and how was it received?\n"
     ]
    }
   ],
   "source": [
    "questions = [item['question'] for item in data]\n",
    "\n",
    "for i, question in enumerate(questions[:5]):\n",
    "    print(f\"Question {i+1}: {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from openai==0.28) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from openai==0.28) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (1.12.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(file_path: str) -> str:\n",
    "    \"\"\"Load OpenAI API key from a file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalResponseGenerator:\n",
    "    def __init__(self, api_key_path: str):\n",
    "        \"\"\"Initialize the generator with path to API key file.\"\"\"\n",
    "        api_key = load_api_key(api_key_path)\n",
    "        openai.api_key = api_key\n",
    "        self.rules = {\n",
    "            \"pronouns\": {\n",
    "                \"name\": \"Personal Pronouns Rule\",\n",
    "                \"accepted\": \"Use personal pronouns, including inclusive 'we'\",\n",
    "                \"rejected\": \"Avoid using any personal pronouns\"\n",
    "            },\n",
    "            \"voice\": {\n",
    "                \"name\": \"Voice Rule\",\n",
    "                \"accepted\": \"Use active voice\",\n",
    "                \"rejected\": \"Use passive voice\"\n",
    "            },\n",
    "            \"tense\": {\n",
    "                \"name\": \"Tense Rule\",\n",
    "                \"accepted\": \"Use present tense\",\n",
    "                \"rejected\": \"Use past tense\"\n",
    "            },\n",
    "            \"mood\": {\n",
    "                \"name\": \"Mood Rule\",\n",
    "                \"accepted\": \"Use polite imperative mood\",\n",
    "                \"rejected\": \"Use imperative mood\"\n",
    "            },\n",
    "            \"emotional\": {\n",
    "                \"name\": \"Emotional Words Rule\",\n",
    "                \"accepted\": \"Use emotional words and cognitive verbs (like feel, understand, think, believe)\",\n",
    "                \"rejected\": \"Avoid using any emotional words or cognitive verbs\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def generate_prompt(self, question: str, rule_key: str, is_accepted: bool) -> str:\n",
    "        \"\"\"Generate a prompt that emphasizes maintaining the same meaning.\"\"\"\n",
    "        rule = self.rules[rule_key]\n",
    "        style = \"accepted\" if is_accepted else \"rejected\"\n",
    "        \n",
    "        prompt = f\"\"\"As a legal assistant, provide a response to the following legal question.\n",
    "\n",
    "        Your response must follow these requirements:\n",
    "        1. MOST IMPORTANT: The factual content and legal meaning of your response must be clear and complete\n",
    "        2. Linguistic Style Rule: {rule[style]}\n",
    "        \n",
    "        Critical Instructions:\n",
    "        - Your response should convey EXACTLY THE SAME legal information and meaning as you would normally provide\n",
    "        - ONLY the linguistic style should change, not the underlying meaning or legal content\n",
    "        - Keep the response concise and limited to a single sentence\n",
    "        - Focus on answering the legal question while maintaining the required linguistic style\n",
    "        \n",
    "        Question: {question}\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "    def get_gpt4_response(self, prompt: str) -> str:\n",
    "        \"\"\"Get response from GPT-4.\"\"\"\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"You are a legal assistant specializing in Australian law cases. Your task is to provide legally accurate responses while following specific linguistic style requirements. The meaning and legal content must remain consistent regardless of the linguistic style used.\"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            return response['choices'][0]['message']['content'].strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting GPT-4 response: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def load_questions(self, file_path: str) -> List[str]:\n",
    "        \"\"\"Load questions from JSONL file.\"\"\"\n",
    "        questions = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                questions.append(data['question'])\n",
    "        return questions\n",
    "\n",
    "    def generate_dataset(self, questions: List[str], rule_key: str) -> pd.DataFrame:\n",
    "        \"\"\"Generate pairs of responses for a specific rule.\"\"\"\n",
    "        data = []\n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"Processing question {i}/{len(questions)} for {self.rules[rule_key]['name']}\")\n",
    "            accepted, rejected = self.generate_response_pair(question, rule_key)\n",
    "            data.append({\n",
    "                'question': question,\n",
    "                'accepted_response': accepted,\n",
    "                'rejected_response': rejected,\n",
    "                'rule': self.rules[rule_key]['name']\n",
    "            })\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def generate_response_pair(self, question: str, rule_key: str) -> Tuple[str, str]:\n",
    "        \"\"\"Generate a pair of responses for a given question and rule.\"\"\"\n",
    "        accepted_prompt = self.generate_prompt(question, rule_key, True)\n",
    "        rejected_prompt = self.generate_prompt(question, rule_key, False)\n",
    "        \n",
    "        accepted_response = self.get_gpt4_response(accepted_prompt)\n",
    "        rejected_response = self.get_gpt4_response(rejected_prompt)\n",
    "        \n",
    "        return accepted_response, rejected_response\n",
    "\n",
    "    def process_all_rules(self, data_path: str, output_dir: str, sample_size: int = None):\n",
    "        \"\"\"Process all rules and save results to separate CSV files.\"\"\"\n",
    "        questions = self.load_questions(data_path)\n",
    "\n",
    "        if sample_size:\n",
    "            questions = questions[:sample_size]\n",
    "            \n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for rule_key in self.rules:\n",
    "            print(f\"\\nProcessing {self.rules[rule_key]['name']}...\")\n",
    "            df = self.generate_dataset(questions, rule_key)\n",
    "            output_path = output_dir / f'responses_{rule_key}.csv'\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = Path(\"/Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/scripts\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = LegalResponseGenerator('api_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_key.txt              langchain_test.ipynb     lexical-frequency.ipynb\n",
      "counsel-gpt-family.ipynb legal-gpt-family.ipynb   \u001b[34muntitled folder\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Personal Pronouns Rule...\n",
      "Processing question 1/30 for Personal Pronouns Rule\n",
      "Processing question 2/30 for Personal Pronouns Rule\n",
      "Processing question 3/30 for Personal Pronouns Rule\n",
      "Processing question 4/30 for Personal Pronouns Rule\n",
      "Processing question 5/30 for Personal Pronouns Rule\n",
      "Processing question 6/30 for Personal Pronouns Rule\n",
      "Processing question 7/30 for Personal Pronouns Rule\n",
      "Processing question 8/30 for Personal Pronouns Rule\n",
      "Processing question 9/30 for Personal Pronouns Rule\n",
      "Processing question 10/30 for Personal Pronouns Rule\n",
      "Processing question 11/30 for Personal Pronouns Rule\n",
      "Processing question 12/30 for Personal Pronouns Rule\n",
      "Processing question 13/30 for Personal Pronouns Rule\n",
      "Processing question 14/30 for Personal Pronouns Rule\n",
      "Processing question 15/30 for Personal Pronouns Rule\n",
      "Processing question 16/30 for Personal Pronouns Rule\n",
      "Processing question 17/30 for Personal Pronouns Rule\n",
      "Processing question 18/30 for Personal Pronouns Rule\n",
      "Processing question 19/30 for Personal Pronouns Rule\n",
      "Processing question 20/30 for Personal Pronouns Rule\n",
      "Processing question 21/30 for Personal Pronouns Rule\n",
      "Processing question 22/30 for Personal Pronouns Rule\n",
      "Processing question 23/30 for Personal Pronouns Rule\n",
      "Processing question 24/30 for Personal Pronouns Rule\n",
      "Processing question 25/30 for Personal Pronouns Rule\n",
      "Processing question 26/30 for Personal Pronouns Rule\n",
      "Processing question 27/30 for Personal Pronouns Rule\n",
      "Processing question 28/30 for Personal Pronouns Rule\n",
      "Processing question 29/30 for Personal Pronouns Rule\n",
      "Processing question 30/30 for Personal Pronouns Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4/test2/responses_pronouns.csv\n",
      "\n",
      "Processing Voice Rule...\n",
      "Processing question 1/30 for Voice Rule\n",
      "Processing question 2/30 for Voice Rule\n",
      "Processing question 3/30 for Voice Rule\n",
      "Processing question 4/30 for Voice Rule\n",
      "Processing question 5/30 for Voice Rule\n",
      "Processing question 6/30 for Voice Rule\n",
      "Processing question 7/30 for Voice Rule\n",
      "Processing question 8/30 for Voice Rule\n",
      "Processing question 9/30 for Voice Rule\n",
      "Processing question 10/30 for Voice Rule\n",
      "Processing question 11/30 for Voice Rule\n",
      "Processing question 12/30 for Voice Rule\n",
      "Processing question 13/30 for Voice Rule\n",
      "Processing question 14/30 for Voice Rule\n",
      "Processing question 15/30 for Voice Rule\n",
      "Processing question 16/30 for Voice Rule\n",
      "Processing question 17/30 for Voice Rule\n",
      "Processing question 18/30 for Voice Rule\n",
      "Processing question 19/30 for Voice Rule\n",
      "Processing question 20/30 for Voice Rule\n",
      "Processing question 21/30 for Voice Rule\n",
      "Processing question 22/30 for Voice Rule\n",
      "Processing question 23/30 for Voice Rule\n",
      "Processing question 24/30 for Voice Rule\n",
      "Processing question 25/30 for Voice Rule\n",
      "Processing question 26/30 for Voice Rule\n",
      "Processing question 27/30 for Voice Rule\n",
      "Processing question 28/30 for Voice Rule\n",
      "Processing question 29/30 for Voice Rule\n",
      "Processing question 30/30 for Voice Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4/test2/responses_voice.csv\n",
      "\n",
      "Processing Tense Rule...\n",
      "Processing question 1/30 for Tense Rule\n",
      "Processing question 2/30 for Tense Rule\n",
      "Processing question 3/30 for Tense Rule\n",
      "Processing question 4/30 for Tense Rule\n",
      "Processing question 5/30 for Tense Rule\n",
      "Processing question 6/30 for Tense Rule\n",
      "Processing question 7/30 for Tense Rule\n",
      "Processing question 8/30 for Tense Rule\n",
      "Processing question 9/30 for Tense Rule\n",
      "Processing question 10/30 for Tense Rule\n",
      "Processing question 11/30 for Tense Rule\n",
      "Processing question 12/30 for Tense Rule\n",
      "Processing question 13/30 for Tense Rule\n",
      "Processing question 14/30 for Tense Rule\n",
      "Processing question 15/30 for Tense Rule\n",
      "Processing question 16/30 for Tense Rule\n",
      "Processing question 17/30 for Tense Rule\n",
      "Processing question 18/30 for Tense Rule\n",
      "Processing question 19/30 for Tense Rule\n",
      "Processing question 20/30 for Tense Rule\n",
      "Processing question 21/30 for Tense Rule\n",
      "Processing question 22/30 for Tense Rule\n",
      "Processing question 23/30 for Tense Rule\n",
      "Processing question 24/30 for Tense Rule\n",
      "Processing question 25/30 for Tense Rule\n",
      "Processing question 26/30 for Tense Rule\n",
      "Processing question 27/30 for Tense Rule\n",
      "Processing question 28/30 for Tense Rule\n",
      "Processing question 29/30 for Tense Rule\n",
      "Processing question 30/30 for Tense Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4/test2/responses_tense.csv\n",
      "\n",
      "Processing Mood Rule...\n",
      "Processing question 1/30 for Mood Rule\n",
      "Processing question 2/30 for Mood Rule\n",
      "Processing question 3/30 for Mood Rule\n",
      "Processing question 4/30 for Mood Rule\n",
      "Processing question 5/30 for Mood Rule\n",
      "Processing question 6/30 for Mood Rule\n",
      "Processing question 7/30 for Mood Rule\n",
      "Processing question 8/30 for Mood Rule\n",
      "Processing question 9/30 for Mood Rule\n",
      "Processing question 10/30 for Mood Rule\n",
      "Processing question 11/30 for Mood Rule\n",
      "Processing question 12/30 for Mood Rule\n",
      "Processing question 13/30 for Mood Rule\n",
      "Processing question 14/30 for Mood Rule\n",
      "Processing question 15/30 for Mood Rule\n",
      "Processing question 16/30 for Mood Rule\n",
      "Processing question 17/30 for Mood Rule\n",
      "Processing question 18/30 for Mood Rule\n",
      "Processing question 19/30 for Mood Rule\n",
      "Processing question 20/30 for Mood Rule\n",
      "Processing question 21/30 for Mood Rule\n",
      "Processing question 22/30 for Mood Rule\n",
      "Processing question 23/30 for Mood Rule\n",
      "Processing question 24/30 for Mood Rule\n",
      "Processing question 25/30 for Mood Rule\n",
      "Processing question 26/30 for Mood Rule\n",
      "Processing question 27/30 for Mood Rule\n",
      "Processing question 28/30 for Mood Rule\n",
      "Processing question 29/30 for Mood Rule\n",
      "Processing question 30/30 for Mood Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4/test2/responses_mood.csv\n",
      "\n",
      "Processing Emotional Words Rule...\n",
      "Processing question 1/30 for Emotional Words Rule\n",
      "Processing question 2/30 for Emotional Words Rule\n",
      "Processing question 3/30 for Emotional Words Rule\n",
      "Processing question 4/30 for Emotional Words Rule\n",
      "Processing question 5/30 for Emotional Words Rule\n",
      "Processing question 6/30 for Emotional Words Rule\n",
      "Processing question 7/30 for Emotional Words Rule\n",
      "Processing question 8/30 for Emotional Words Rule\n",
      "Processing question 9/30 for Emotional Words Rule\n",
      "Processing question 10/30 for Emotional Words Rule\n",
      "Processing question 11/30 for Emotional Words Rule\n",
      "Processing question 12/30 for Emotional Words Rule\n",
      "Processing question 13/30 for Emotional Words Rule\n",
      "Processing question 14/30 for Emotional Words Rule\n",
      "Processing question 15/30 for Emotional Words Rule\n",
      "Processing question 16/30 for Emotional Words Rule\n",
      "Processing question 17/30 for Emotional Words Rule\n",
      "Processing question 18/30 for Emotional Words Rule\n",
      "Processing question 19/30 for Emotional Words Rule\n",
      "Processing question 20/30 for Emotional Words Rule\n",
      "Processing question 21/30 for Emotional Words Rule\n",
      "Processing question 22/30 for Emotional Words Rule\n",
      "Processing question 23/30 for Emotional Words Rule\n",
      "Processing question 24/30 for Emotional Words Rule\n",
      "Processing question 25/30 for Emotional Words Rule\n",
      "Processing question 26/30 for Emotional Words Rule\n",
      "Processing question 27/30 for Emotional Words Rule\n",
      "Processing question 28/30 for Emotional Words Rule\n",
      "Processing question 29/30 for Emotional Words Rule\n",
      "Processing question 30/30 for Emotional Words Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4/test2/responses_emotional.csv\n"
     ]
    }
   ],
   "source": [
    "generator.process_all_rules(\n",
    "    data_path = HOME_DIR / 'public-data' / 'open-australian-legal-qa' / 'qa.jsonl',\n",
    "    output_dir = HOME_DIR / 'generated-data' / 'open-australian-legal-qa' / 'GPT-4' / 'test2',\n",
    "    sample_size = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InstructGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalResponseGenerator:\n",
    "    def __init__(self, api_key_path: str):\n",
    "        \"\"\"Initialize the generator with path to API key file.\"\"\"\n",
    "        api_key = load_api_key(api_key_path)\n",
    "        openai.api_key = api_key\n",
    "        self.rules = {\n",
    "            \"pronouns\": {\n",
    "                \"name\": \"Personal Pronouns Rule\",\n",
    "                \"accepted\": \"Use personal pronouns, including inclusive 'we'\",\n",
    "                \"rejected\": \"Avoid using any personal pronouns\"\n",
    "            },\n",
    "            \"voice\": {\n",
    "                \"name\": \"Voice Rule\",\n",
    "                \"accepted\": \"Use active voice\",\n",
    "                \"rejected\": \"Use passive voice\"\n",
    "            },\n",
    "            \"tense\": {\n",
    "                \"name\": \"Tense Rule\",\n",
    "                \"accepted\": \"Use present tense\",\n",
    "                \"rejected\": \"Use past tense\"\n",
    "            },\n",
    "            \"mood\": {\n",
    "                \"name\": \"Mood Rule\",\n",
    "                \"accepted\": \"Use polite imperative mood\",\n",
    "                \"rejected\": \"Use imperative mood\"\n",
    "            },\n",
    "            \"emotional\": {\n",
    "                \"name\": \"Emotional Words Rule\",\n",
    "                \"accepted\": \"Use emotional words and cognitive verbs (like feel, understand, think, believe)\",\n",
    "                \"rejected\": \"Avoid using any emotional words or cognitive verbs\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def generate_prompt(self, question: str, rule_key: str, is_accepted: bool) -> str:\n",
    "        \"\"\"Generate a prompt that emphasizes maintaining the same meaning.\"\"\"\n",
    "        rule = self.rules[rule_key]\n",
    "        style = \"accepted\" if is_accepted else \"rejected\"\n",
    "        \n",
    "        prompt = f\"\"\"You are a legal assistant specializing in Australian law cases. Your task is to provide legally accurate responses while following specific linguistic style requirements. The meaning and legal content must remain consistent regardless of the linguistic style used.\n",
    "\n",
    "As a legal assistant, provide a response to the following legal question.\n",
    "\n",
    "Your response must follow these requirements:\n",
    "1. MOST IMPORTANT: The factual content and legal meaning of your response must be clear and complete\n",
    "2. Linguistic Style Rule: {rule[style]}\n",
    "\n",
    "Critical Instructions:\n",
    "- Your response should convey EXACTLY THE SAME legal information and meaning as you would normally provide\n",
    "- ONLY the linguistic style should change, not the underlying meaning or legal content\n",
    "- Keep the response concise and limited to a single sentence\n",
    "- Focus on answering the legal question while maintaining the required linguistic style\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "    def get_instruct_response(self, prompt: str) -> str:\n",
    "            \"\"\"Get response using gpt-3.5-turbo.\"\"\"\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=150\n",
    "                )\n",
    "                return response.choices[0].message['content'].strip()\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting GPT response: {e}\")\n",
    "                return \"\"\n",
    "\n",
    "    def load_questions(self, file_path: str) -> List[str]:\n",
    "        \"\"\"Load questions from JSONL file.\"\"\"\n",
    "        questions = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                questions.append(data['question'])\n",
    "        return questions\n",
    "\n",
    "    def generate_dataset(self, questions: List[str], rule_key: str) -> pd.DataFrame:\n",
    "        \"\"\"Generate pairs of responses for a specific rule.\"\"\"\n",
    "        data = []\n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"Processing question {i}/{len(questions)} for {self.rules[rule_key]['name']}\")\n",
    "            accepted, rejected = self.generate_response_pair(question, rule_key)\n",
    "            data.append({\n",
    "                'question': question,\n",
    "                'accepted_response': accepted,\n",
    "                'rejected_response': rejected,\n",
    "                'rule': self.rules[rule_key]['name']\n",
    "            })\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def generate_response_pair(self, question: str, rule_key: str) -> Tuple[str, str]:\n",
    "        \"\"\"Generate a pair of responses for a given question and rule.\"\"\"\n",
    "        accepted_prompt = self.generate_prompt(question, rule_key, True)\n",
    "        rejected_prompt = self.generate_prompt(question, rule_key, False)\n",
    "        \n",
    "        accepted_response = self.get_instruct_response(accepted_prompt)\n",
    "        rejected_response = self.get_instruct_response(rejected_prompt)\n",
    "        \n",
    "        return accepted_response, rejected_response\n",
    "\n",
    "    def process_all_rules(self, data_path: str, output_dir: str, sample_size: int = None):\n",
    "        \"\"\"Process all rules and save results to separate CSV files.\"\"\"\n",
    "        questions = self.load_questions(data_path)\n",
    "        \n",
    "        if sample_size:\n",
    "            questions = questions[:sample_size]\n",
    "            \n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for rule_key in self.rules:\n",
    "            print(f\"\\nProcessing {self.rules[rule_key]['name']}...\")\n",
    "            df = self.generate_dataset(questions, rule_key)\n",
    "            output_path = output_dir / f'responses_{rule_key}.csv'\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_gpt_generator = LegalResponseGenerator('api_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Personal Pronouns Rule...\n",
      "Processing question 1/30 for Personal Pronouns Rule\n",
      "Processing question 2/30 for Personal Pronouns Rule\n",
      "Processing question 3/30 for Personal Pronouns Rule\n",
      "Processing question 4/30 for Personal Pronouns Rule\n",
      "Processing question 5/30 for Personal Pronouns Rule\n",
      "Processing question 6/30 for Personal Pronouns Rule\n",
      "Processing question 7/30 for Personal Pronouns Rule\n",
      "Processing question 8/30 for Personal Pronouns Rule\n",
      "Processing question 9/30 for Personal Pronouns Rule\n",
      "Processing question 10/30 for Personal Pronouns Rule\n",
      "Processing question 11/30 for Personal Pronouns Rule\n",
      "Processing question 12/30 for Personal Pronouns Rule\n",
      "Processing question 13/30 for Personal Pronouns Rule\n",
      "Processing question 14/30 for Personal Pronouns Rule\n",
      "Processing question 15/30 for Personal Pronouns Rule\n",
      "Processing question 16/30 for Personal Pronouns Rule\n",
      "Processing question 17/30 for Personal Pronouns Rule\n",
      "Processing question 18/30 for Personal Pronouns Rule\n",
      "Processing question 19/30 for Personal Pronouns Rule\n",
      "Processing question 20/30 for Personal Pronouns Rule\n",
      "Processing question 21/30 for Personal Pronouns Rule\n",
      "Processing question 22/30 for Personal Pronouns Rule\n",
      "Processing question 23/30 for Personal Pronouns Rule\n",
      "Processing question 24/30 for Personal Pronouns Rule\n",
      "Processing question 25/30 for Personal Pronouns Rule\n",
      "Processing question 26/30 for Personal Pronouns Rule\n",
      "Processing question 27/30 for Personal Pronouns Rule\n",
      "Processing question 28/30 for Personal Pronouns Rule\n",
      "Processing question 29/30 for Personal Pronouns Rule\n",
      "Processing question 30/30 for Personal Pronouns Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test/responses_pronouns.csv\n",
      "\n",
      "Processing Voice Rule...\n",
      "Processing question 1/30 for Voice Rule\n",
      "Processing question 2/30 for Voice Rule\n",
      "Processing question 3/30 for Voice Rule\n",
      "Processing question 4/30 for Voice Rule\n",
      "Processing question 5/30 for Voice Rule\n",
      "Processing question 6/30 for Voice Rule\n",
      "Processing question 7/30 for Voice Rule\n",
      "Processing question 8/30 for Voice Rule\n",
      "Processing question 9/30 for Voice Rule\n",
      "Processing question 10/30 for Voice Rule\n",
      "Processing question 11/30 for Voice Rule\n",
      "Processing question 12/30 for Voice Rule\n",
      "Processing question 13/30 for Voice Rule\n",
      "Processing question 14/30 for Voice Rule\n",
      "Processing question 15/30 for Voice Rule\n",
      "Processing question 16/30 for Voice Rule\n",
      "Processing question 17/30 for Voice Rule\n",
      "Processing question 18/30 for Voice Rule\n",
      "Processing question 19/30 for Voice Rule\n",
      "Processing question 20/30 for Voice Rule\n",
      "Processing question 21/30 for Voice Rule\n",
      "Processing question 22/30 for Voice Rule\n",
      "Processing question 23/30 for Voice Rule\n",
      "Processing question 24/30 for Voice Rule\n",
      "Processing question 25/30 for Voice Rule\n",
      "Processing question 26/30 for Voice Rule\n",
      "Processing question 27/30 for Voice Rule\n",
      "Processing question 28/30 for Voice Rule\n",
      "Processing question 29/30 for Voice Rule\n",
      "Processing question 30/30 for Voice Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test/responses_voice.csv\n",
      "\n",
      "Processing Tense Rule...\n",
      "Processing question 1/30 for Tense Rule\n",
      "Processing question 2/30 for Tense Rule\n",
      "Processing question 3/30 for Tense Rule\n",
      "Processing question 4/30 for Tense Rule\n",
      "Processing question 5/30 for Tense Rule\n",
      "Processing question 6/30 for Tense Rule\n",
      "Processing question 7/30 for Tense Rule\n",
      "Processing question 8/30 for Tense Rule\n",
      "Processing question 9/30 for Tense Rule\n",
      "Processing question 10/30 for Tense Rule\n",
      "Processing question 11/30 for Tense Rule\n",
      "Processing question 12/30 for Tense Rule\n",
      "Processing question 13/30 for Tense Rule\n",
      "Processing question 14/30 for Tense Rule\n",
      "Processing question 15/30 for Tense Rule\n",
      "Processing question 16/30 for Tense Rule\n",
      "Processing question 17/30 for Tense Rule\n",
      "Processing question 18/30 for Tense Rule\n",
      "Processing question 19/30 for Tense Rule\n",
      "Processing question 20/30 for Tense Rule\n",
      "Processing question 21/30 for Tense Rule\n",
      "Processing question 22/30 for Tense Rule\n",
      "Processing question 23/30 for Tense Rule\n",
      "Processing question 24/30 for Tense Rule\n",
      "Processing question 25/30 for Tense Rule\n",
      "Processing question 26/30 for Tense Rule\n",
      "Processing question 27/30 for Tense Rule\n",
      "Processing question 28/30 for Tense Rule\n",
      "Processing question 29/30 for Tense Rule\n",
      "Processing question 30/30 for Tense Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test/responses_tense.csv\n",
      "\n",
      "Processing Mood Rule...\n",
      "Processing question 1/30 for Mood Rule\n",
      "Processing question 2/30 for Mood Rule\n",
      "Processing question 3/30 for Mood Rule\n",
      "Processing question 4/30 for Mood Rule\n",
      "Processing question 5/30 for Mood Rule\n",
      "Processing question 6/30 for Mood Rule\n",
      "Processing question 7/30 for Mood Rule\n",
      "Processing question 8/30 for Mood Rule\n",
      "Processing question 9/30 for Mood Rule\n",
      "Processing question 10/30 for Mood Rule\n",
      "Processing question 11/30 for Mood Rule\n",
      "Processing question 12/30 for Mood Rule\n",
      "Processing question 13/30 for Mood Rule\n",
      "Processing question 14/30 for Mood Rule\n",
      "Processing question 15/30 for Mood Rule\n",
      "Processing question 16/30 for Mood Rule\n",
      "Processing question 17/30 for Mood Rule\n",
      "Processing question 18/30 for Mood Rule\n",
      "Processing question 19/30 for Mood Rule\n",
      "Processing question 20/30 for Mood Rule\n",
      "Processing question 21/30 for Mood Rule\n",
      "Processing question 22/30 for Mood Rule\n",
      "Processing question 23/30 for Mood Rule\n",
      "Processing question 24/30 for Mood Rule\n",
      "Processing question 25/30 for Mood Rule\n",
      "Processing question 26/30 for Mood Rule\n",
      "Processing question 27/30 for Mood Rule\n",
      "Processing question 28/30 for Mood Rule\n",
      "Processing question 29/30 for Mood Rule\n",
      "Processing question 30/30 for Mood Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test/responses_mood.csv\n",
      "\n",
      "Processing Emotional Words Rule...\n",
      "Processing question 1/30 for Emotional Words Rule\n",
      "Processing question 2/30 for Emotional Words Rule\n",
      "Processing question 3/30 for Emotional Words Rule\n",
      "Processing question 4/30 for Emotional Words Rule\n",
      "Processing question 5/30 for Emotional Words Rule\n",
      "Processing question 6/30 for Emotional Words Rule\n",
      "Processing question 7/30 for Emotional Words Rule\n",
      "Processing question 8/30 for Emotional Words Rule\n",
      "Processing question 9/30 for Emotional Words Rule\n",
      "Processing question 10/30 for Emotional Words Rule\n",
      "Processing question 11/30 for Emotional Words Rule\n",
      "Processing question 12/30 for Emotional Words Rule\n",
      "Processing question 13/30 for Emotional Words Rule\n",
      "Processing question 14/30 for Emotional Words Rule\n",
      "Processing question 15/30 for Emotional Words Rule\n",
      "Processing question 16/30 for Emotional Words Rule\n",
      "Processing question 17/30 for Emotional Words Rule\n",
      "Processing question 18/30 for Emotional Words Rule\n",
      "Processing question 19/30 for Emotional Words Rule\n",
      "Processing question 20/30 for Emotional Words Rule\n",
      "Processing question 21/30 for Emotional Words Rule\n",
      "Processing question 22/30 for Emotional Words Rule\n",
      "Processing question 23/30 for Emotional Words Rule\n",
      "Processing question 24/30 for Emotional Words Rule\n",
      "Processing question 25/30 for Emotional Words Rule\n",
      "Processing question 26/30 for Emotional Words Rule\n",
      "Processing question 27/30 for Emotional Words Rule\n",
      "Processing question 28/30 for Emotional Words Rule\n",
      "Processing question 29/30 for Emotional Words Rule\n",
      "Processing question 30/30 for Emotional Words Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test/responses_emotional.csv\n"
     ]
    }
   ],
   "source": [
    "instruct_gpt_generator.process_all_rules(\n",
    "    data_path = HOME_DIR / 'public-data' / 'open-australian-legal-qa' / 'qa.jsonl',\n",
    "    output_dir = HOME_DIR / 'generated-data' / 'open-australian-legal-qa' / 'InstructGPT' / 'test',\n",
    "    sample_size = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalResponseGenerator:\n",
    "    def __init__(self, api_key_path: str):\n",
    "        \"\"\"Initialize the generator with path to API key file.\"\"\"\n",
    "        api_key = load_api_key(api_key_path)\n",
    "        openai.api_key = api_key\n",
    "        self.rules = {\n",
    "            \"pronouns\": {\n",
    "                \"name\": \"Personal Pronouns Rule\",\n",
    "                \"accepted\": \"Use personal pronouns, including inclusive 'we'\",\n",
    "                \"rejected\": \"Avoid using any personal pronouns\"\n",
    "            },\n",
    "            \"voice\": {\n",
    "                \"name\": \"Voice Rule\",\n",
    "                \"accepted\": \"Use active voice\",\n",
    "                \"rejected\": \"Use passive voice\"\n",
    "            },\n",
    "            \"tense\": {\n",
    "                \"name\": \"Tense Rule\",\n",
    "                \"accepted\": \"Use present tense\",\n",
    "                \"rejected\": \"Use past tense\"\n",
    "            },\n",
    "            \"mood\": {\n",
    "                \"name\": \"Mood Rule\",\n",
    "                \"accepted\": \"Use polite imperative mood\",\n",
    "                \"rejected\": \"Use imperative mood\"\n",
    "            },\n",
    "            \"emotional\": {\n",
    "                \"name\": \"Emotional Words Rule\",\n",
    "                \"accepted\": \"Use emotional words and cognitive verbs (like feel, understand, think, believe)\",\n",
    "                \"rejected\": \"Avoid using any emotional words or cognitive verbs\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def generate_prompt(self, question: str, rule_key: str, is_accepted: bool) -> str:\n",
    "        \"\"\"Generate a prompt that emphasizes maintaining the same meaning.\"\"\"\n",
    "        rule = self.rules[rule_key]\n",
    "        style = \"accepted\" if is_accepted else \"rejected\"\n",
    "        \n",
    "        prompt = f\"\"\"As a legal assistant, provide a response to the following legal question.\n",
    "\n",
    "        Your response must follow these requirements:\n",
    "        1. MOST IMPORTANT: The factual content and legal meaning of your response must be clear and complete\n",
    "        2. Linguistic Style Rule: {rule[style]}\n",
    "        \n",
    "        Critical Instructions:\n",
    "        - Your response should convey EXACTLY THE SAME legal information and meaning as you would normally provide\n",
    "        - ONLY the linguistic style should change, not the underlying meaning or legal content\n",
    "        - Keep the response concise and limited to a single sentence\n",
    "        - Focus on answering the legal question while maintaining the required linguistic style\n",
    "        \n",
    "        Question: {question}\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "    def get_gpt4_response(self, prompt: str) -> str:\n",
    "            \"\"\"Get response from latest GPT-4.\"\"\"\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4-0125-preview\",\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\", \n",
    "                            \"content\": \"You are a legal assistant specializing in Australian law cases. Your task is to provide legally accurate responses while following specific linguistic style requirements. The meaning and legal content must remain consistent regardless of the linguistic style used.\"\n",
    "                        },\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=150\n",
    "                )\n",
    "                return response.choices[0].message['content'].strip()\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting GPT-4 response: {e}\")\n",
    "                return \"\"\n",
    "\n",
    "    def load_questions(self, file_path: str) -> List[str]:\n",
    "        \"\"\"Load questions from JSONL file.\"\"\"\n",
    "        questions = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                questions.append(data['question'])\n",
    "        return questions\n",
    "\n",
    "    def generate_dataset(self, questions: List[str], rule_key: str) -> pd.DataFrame:\n",
    "        \"\"\"Generate pairs of responses for a specific rule.\"\"\"\n",
    "        data = []\n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"Processing question {i}/{len(questions)} for {self.rules[rule_key]['name']}\")\n",
    "            accepted, rejected = self.generate_response_pair(question, rule_key)\n",
    "            data.append({\n",
    "                'question': question,\n",
    "                'accepted_response': accepted,\n",
    "                'rejected_response': rejected,\n",
    "                'rule': self.rules[rule_key]['name']\n",
    "            })\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def generate_response_pair(self, question: str, rule_key: str) -> Tuple[str, str]:\n",
    "        \"\"\"Generate a pair of responses for a given question and rule.\"\"\"\n",
    "        accepted_prompt = self.generate_prompt(question, rule_key, True)\n",
    "        rejected_prompt = self.generate_prompt(question, rule_key, False)\n",
    "        \n",
    "        accepted_response = self.get_gpt4_response(accepted_prompt)\n",
    "        rejected_response = self.get_gpt4_response(rejected_prompt)\n",
    "        \n",
    "        return accepted_response, rejected_response\n",
    "\n",
    "    def process_all_rules(self, data_path: str, output_dir: str, sample_size: int = None):\n",
    "        \"\"\"Process all rules and save results to separate CSV files.\"\"\"\n",
    "        questions = self.load_questions(data_path)\n",
    "        \n",
    "        if sample_size:\n",
    "            questions = questions[:sample_size]\n",
    "            \n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for rule_key in self.rules:\n",
    "            print(f\"\\nProcessing {self.rules[rule_key]['name']}...\")\n",
    "            df = self.generate_dataset(questions, rule_key)\n",
    "            output_path = output_dir / f'responses_{rule_key}.csv'\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_generator = LegalResponseGenerator('api_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Personal Pronouns Rule...\n",
      "Processing question 1/20 for Personal Pronouns Rule\n",
      "Processing question 2/20 for Personal Pronouns Rule\n",
      "Processing question 3/20 for Personal Pronouns Rule\n",
      "Processing question 4/20 for Personal Pronouns Rule\n",
      "Processing question 5/20 for Personal Pronouns Rule\n",
      "Processing question 6/20 for Personal Pronouns Rule\n",
      "Processing question 7/20 for Personal Pronouns Rule\n",
      "Processing question 8/20 for Personal Pronouns Rule\n",
      "Processing question 9/20 for Personal Pronouns Rule\n",
      "Processing question 10/20 for Personal Pronouns Rule\n",
      "Processing question 11/20 for Personal Pronouns Rule\n",
      "Processing question 12/20 for Personal Pronouns Rule\n",
      "Processing question 13/20 for Personal Pronouns Rule\n",
      "Processing question 14/20 for Personal Pronouns Rule\n",
      "Processing question 15/20 for Personal Pronouns Rule\n",
      "Processing question 16/20 for Personal Pronouns Rule\n",
      "Processing question 17/20 for Personal Pronouns Rule\n",
      "Processing question 18/20 for Personal Pronouns Rule\n",
      "Processing question 19/20 for Personal Pronouns Rule\n",
      "Processing question 20/20 for Personal Pronouns Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test/responses_pronouns.csv\n",
      "\n",
      "Processing Voice Rule...\n",
      "Processing question 1/20 for Voice Rule\n",
      "Processing question 2/20 for Voice Rule\n",
      "Processing question 3/20 for Voice Rule\n",
      "Processing question 4/20 for Voice Rule\n",
      "Processing question 5/20 for Voice Rule\n",
      "Processing question 6/20 for Voice Rule\n",
      "Processing question 7/20 for Voice Rule\n",
      "Processing question 8/20 for Voice Rule\n",
      "Processing question 9/20 for Voice Rule\n",
      "Processing question 10/20 for Voice Rule\n",
      "Processing question 11/20 for Voice Rule\n",
      "Processing question 12/20 for Voice Rule\n",
      "Processing question 13/20 for Voice Rule\n",
      "Processing question 14/20 for Voice Rule\n",
      "Processing question 15/20 for Voice Rule\n",
      "Processing question 16/20 for Voice Rule\n",
      "Processing question 17/20 for Voice Rule\n",
      "Processing question 18/20 for Voice Rule\n",
      "Processing question 19/20 for Voice Rule\n",
      "Processing question 20/20 for Voice Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test/responses_voice.csv\n",
      "\n",
      "Processing Tense Rule...\n",
      "Processing question 1/20 for Tense Rule\n",
      "Processing question 2/20 for Tense Rule\n",
      "Processing question 3/20 for Tense Rule\n",
      "Processing question 4/20 for Tense Rule\n",
      "Processing question 5/20 for Tense Rule\n",
      "Processing question 6/20 for Tense Rule\n",
      "Processing question 7/20 for Tense Rule\n",
      "Processing question 8/20 for Tense Rule\n",
      "Processing question 9/20 for Tense Rule\n",
      "Processing question 10/20 for Tense Rule\n",
      "Processing question 11/20 for Tense Rule\n",
      "Processing question 12/20 for Tense Rule\n",
      "Processing question 13/20 for Tense Rule\n",
      "Processing question 14/20 for Tense Rule\n",
      "Processing question 15/20 for Tense Rule\n",
      "Processing question 16/20 for Tense Rule\n",
      "Processing question 17/20 for Tense Rule\n",
      "Processing question 18/20 for Tense Rule\n",
      "Processing question 19/20 for Tense Rule\n",
      "Processing question 20/20 for Tense Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test/responses_tense.csv\n",
      "\n",
      "Processing Mood Rule...\n",
      "Processing question 1/20 for Mood Rule\n",
      "Processing question 2/20 for Mood Rule\n",
      "Processing question 3/20 for Mood Rule\n",
      "Processing question 4/20 for Mood Rule\n",
      "Processing question 5/20 for Mood Rule\n",
      "Processing question 6/20 for Mood Rule\n",
      "Processing question 7/20 for Mood Rule\n",
      "Processing question 8/20 for Mood Rule\n",
      "Processing question 9/20 for Mood Rule\n",
      "Processing question 10/20 for Mood Rule\n",
      "Processing question 11/20 for Mood Rule\n",
      "Processing question 12/20 for Mood Rule\n",
      "Processing question 13/20 for Mood Rule\n",
      "Processing question 14/20 for Mood Rule\n",
      "Processing question 15/20 for Mood Rule\n",
      "Processing question 16/20 for Mood Rule\n",
      "Processing question 17/20 for Mood Rule\n",
      "Processing question 18/20 for Mood Rule\n",
      "Processing question 19/20 for Mood Rule\n",
      "Processing question 20/20 for Mood Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test/responses_mood.csv\n",
      "\n",
      "Processing Emotional Words Rule...\n",
      "Processing question 1/20 for Emotional Words Rule\n",
      "Processing question 2/20 for Emotional Words Rule\n",
      "Processing question 3/20 for Emotional Words Rule\n",
      "Processing question 4/20 for Emotional Words Rule\n",
      "Processing question 5/20 for Emotional Words Rule\n",
      "Processing question 6/20 for Emotional Words Rule\n",
      "Processing question 7/20 for Emotional Words Rule\n",
      "Processing question 8/20 for Emotional Words Rule\n",
      "Processing question 9/20 for Emotional Words Rule\n",
      "Processing question 10/20 for Emotional Words Rule\n",
      "Processing question 11/20 for Emotional Words Rule\n",
      "Processing question 12/20 for Emotional Words Rule\n",
      "Processing question 13/20 for Emotional Words Rule\n",
      "Processing question 14/20 for Emotional Words Rule\n",
      "Processing question 15/20 for Emotional Words Rule\n",
      "Processing question 16/20 for Emotional Words Rule\n",
      "Processing question 17/20 for Emotional Words Rule\n",
      "Processing question 18/20 for Emotional Words Rule\n",
      "Processing question 19/20 for Emotional Words Rule\n",
      "Processing question 20/20 for Emotional Words Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test/responses_emotional.csv\n"
     ]
    }
   ],
   "source": [
    "gpt4o_generator.process_all_rules(\n",
    "    data_path = HOME_DIR / 'public-data' / 'open-australian-legal-qa' / 'qa.jsonl',\n",
    "    output_dir = HOME_DIR / 'generated-data' / 'open-australian-legal-qa' / 'GPT-4o' / 'test',\n",
    "    sample_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Uploading Generated Data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(tokenizer, dataset_name, input_min_text_length=2, input_max_text_length=8):\n",
    "    EOS_TOKEN = tokenizer.eos_token\n",
    "    train_dataset = load_dataset(dataset_name)\n",
    "    num_proc = 4\n",
    "\n",
    "    # Accepted Prompt (with rules)\n",
    "    system_input_with_rules = generate_accepted_prompt()\n",
    "\n",
    "    # Rejected Prompt (rules negated)\n",
    "    system_input_without_rules = generate_rejected_prompt()\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        new_examples = {\n",
    "            \"accepted\": [],\n",
    "            \"rejected\": [],\n",
    "            \"accepted_input_ids\": [],\n",
    "            \"rejected_input_ids\": [],\n",
    "        }\n",
    "        for question in examples[\"question\"]:\n",
    "            # Accepted Version\n",
    "            accepted_prompt = f\"### System:\\n{system_input_with_rules}\\n### User:\\n{question}\\n### Assistant:\\n\"\n",
    "            accepted_query = accepted_prompt + EOS_TOKEN\n",
    "            tokenized_accepted = tokenizer(accepted_query, truncation=True)\n",
    "\n",
    "            # Rejected Version\n",
    "            rejected_prompt = f\"### System:\\n{system_input_without_rules}\\n### User:\\n{question}\\n### Assistant:\\n\"\n",
    "            rejected_query = rejected_prompt + EOS_TOKEN\n",
    "            tokenized_rejected = tokenizer(rejected_query, truncation=True)\n",
    "\n",
    "            # Add to dataset\n",
    "            new_examples[\"accepted\"].append(accepted_query)\n",
    "            new_examples[\"rejected\"].append(rejected_query)\n",
    "            new_examples[\"accepted_input_ids\"].append(tokenized_accepted[\"input_ids\"])\n",
    "            new_examples[\"rejected_input_ids\"].append(tokenized_rejected[\"input_ids\"])\n",
    "\n",
    "        return new_examples\n",
    "\n",
    "    # Apply preprocessing to dataset\n",
    "    ds = train_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        num_proc=num_proc,\n",
    "    )\n",
    "\n",
    "    # Filter for maximum length\n",
    "    ds = ds.filter(\n",
    "        lambda x: len(x[\"accepted_input_ids\"]) < 2048 and len(x[\"rejected_input_ids\"]) < 2048,\n",
    "        batched=False\n",
    "    )\n",
    "\n",
    "    # Set final dataset format\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(tokenizer, \"dataset_name\")\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "  return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(tokenizer, \"elsayedissa/alignment-questions\")\n",
    "dataset['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckj-speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
