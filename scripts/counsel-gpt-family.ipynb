{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Any, Dict, List\n",
    "from pathlib import Path\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = Path(\"/Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/\")\n",
    "data_path = HOME_DIR / 'public-data' / 'counsel-chat' / 'counsel_chat_250-tokens_full.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_structure(data: Any, prefix: str = \"\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Recursively analyzes the structure of nested JSON data\n",
    "    \n",
    "    Args:\n",
    "        data: JSON data (can be dict, list, or primitive type)\n",
    "        prefix: Current path prefix for nested structures\n",
    "    \n",
    "    Returns:\n",
    "        List of structure descriptions\n",
    "    \"\"\"\n",
    "    structure = []\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            current_path = f\"{prefix}.{key}\" if prefix else key\n",
    "            if isinstance(value, (dict, list)):\n",
    "                structure.extend(analyze_structure(value, current_path))\n",
    "            else:\n",
    "                structure.append(f\"{current_path}: {type(value).__name__}\")\n",
    "                \n",
    "    elif isinstance(data, list) and len(data) > 0:\n",
    "        # Analyze first item in list for structure\n",
    "        sample_item = data[0]\n",
    "        current_path = f\"{prefix}[]\" if prefix else \"[]\"\n",
    "        if isinstance(sample_item, (dict, list)):\n",
    "            structure.extend(analyze_structure(sample_item, current_path))\n",
    "        else:\n",
    "            structure.append(f\"{current_path}: {type(sample_item).__name__}\")\n",
    "            \n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_json_file(file_path: str):\n",
    "    \"\"\"\n",
    "    Reads and analyzes the structure of a JSON file, including nested structures\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "        # 1. Analyze overall structure\n",
    "        print(\"\\n=== JSON File Structure ===\")\n",
    "        if isinstance(data, list):\n",
    "            print(f\"Root type: List (Total {len(data)} items)\")\n",
    "        else:\n",
    "            print(\"Root type: Dictionary\")\n",
    "            \n",
    "        # 2. Print complete structure with nested keys\n",
    "        print(\"\\n=== Complete Structure ===\")\n",
    "        structure = analyze_structure(data)\n",
    "        for item in structure:\n",
    "            print(f\"- {item}\")\n",
    "                \n",
    "        # 3. Print sample data\n",
    "        print(\"\\n=== Sample Data (First Few Items) ===\")\n",
    "        if isinstance(data, list):\n",
    "            sample_data = data[:2]  # First 2 items if list\n",
    "        elif isinstance(data, dict):\n",
    "            # For nested structures, try to get a representative sample\n",
    "            sample_data = {}\n",
    "            for key, value in data.items():\n",
    "                if isinstance(value, list):\n",
    "                    sample_data[key] = value[:2] if value else []  # First 2 items of list\n",
    "                else:\n",
    "                    sample_data[key] = value\n",
    "        \n",
    "        print(json.dumps(sample_data, indent=2, ensure_ascii=False)[:1000] + \"...\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in '{file_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Unexpected error occurred - {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_single_example(file_path: Path):\n",
    "    \"\"\"\n",
    "    Prints a single, complete example from the JSON file in a readable format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Get first example from train data\n",
    "        first_example = data['train'][0]\n",
    "        \n",
    "        print(\"\\n=== Single Training Example ===\")\n",
    "        print(\"\\n1. Personality:\")\n",
    "        for p in first_example['personality']:\n",
    "            print(f\"   {p}\" if p else \"   [empty string]\")\n",
    "        \n",
    "        print(\"\\n2. Utterances:\")\n",
    "        first_utterance = first_example['utterances'][0]\n",
    "        \n",
    "        print(\"\\n   History:\")\n",
    "        for idx, h in enumerate(first_utterance['history'], 1):\n",
    "            print(f\"   {idx}. {h}\")\n",
    "        \n",
    "        print(\"\\n   Candidates (possible responses):\")\n",
    "        for idx, c in enumerate(first_utterance['candidates'], 1):\n",
    "            print(f\"   {idx}. {c}\\n\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_histories(file_path: Path, num_examples: int = 5):\n",
    "    \"\"\"\n",
    "    Prints specified number of history examples from train data\n",
    "    \n",
    "    Args:\n",
    "        file_path (Path): Path to the JSON file\n",
    "        num_examples (int): Number of examples to show (default: 5)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        print(f\"\\n=== First {num_examples} Training Histories ===\\n\")\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            history = data['train'][i]['utterances'][0]['history'][0]\n",
    "            print(f\"Example {i+1}:\")\n",
    "            print(f\"{history}\")\n",
    "            print(\"-\" * 80 + \"\\n\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in '{file_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Unexpected error occurred - {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== JSON File Structure ===\n",
      "Root type: Dictionary\n",
      "\n",
      "=== Complete Structure ===\n",
      "- train[].personality[]: str\n",
      "- train[].utterances[].history[]: str\n",
      "- train[].utterances[].candidates[]: str\n",
      "- valid[].personality[]: str\n",
      "- valid[].utterances[].history[]: str\n",
      "- valid[].utterances[].candidates[]: str\n",
      "\n",
      "=== Sample Data (First Few Items) ===\n",
      "{\n",
      "  \"train\": [\n",
      "    {\n",
      "      \"personality\": [\n",
      "        \"\"\n",
      "      ],\n",
      "      \"utterances\": [\n",
      "        {\n",
      "          \"history\": [\n",
      "            \"can i change my feeling of being worthless to everyone ? i ' m going through some things with my feelings and myself . i barely sleep and i do nothing but think about how i ' m worthless and how i shouldn ' t be here . i ' ve never tried or contemplated suicide . i ' ve always wanted to fix my issues , but i never get around to it . how can i change my feeling of being worthless to everyone ?\"\n",
      "          ],\n",
      "          \"candidates\": [\n",
      "            \"maybe lower your expectations for a bit\",\n",
      "            \"if you are whole - heartedly committed to moving past the sexual and romantic parts of your relationship and just having a friendship than refraining from all the touching would be a good place to start\",\n",
      "            \"very often , one person wants to deal with the conflict right away or shortly thereafter and the other person wants to wait\",\n",
      "            \"\\\" my b...\n"
     ]
    }
   ],
   "source": [
    "analyze_json_file(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Single Training Example ===\n",
      "\n",
      "1. Personality:\n",
      "   [empty string]\n",
      "\n",
      "2. Utterances:\n",
      "\n",
      "   History:\n",
      "   1. can i change my feeling of being worthless to everyone ? i ' m going through some things with my feelings and myself . i barely sleep and i do nothing but think about how i ' m worthless and how i shouldn ' t be here . i ' ve never tried or contemplated suicide . i ' ve always wanted to fix my issues , but i never get around to it . how can i change my feeling of being worthless to everyone ?\n",
      "\n",
      "   Candidates (possible responses):\n",
      "   1. maybe lower your expectations for a bit\n",
      "\n",
      "   2. if you are whole - heartedly committed to moving past the sexual and romantic parts of your relationship and just having a friendship than refraining from all the touching would be a good place to start\n",
      "\n",
      "   3. very often , one person wants to deal with the conflict right away or shortly thereafter and the other person wants to wait\n",
      "\n",
      "   4. \" my best guess is that your boyfriend is triggered by some previous relationship , either romantic or in childhood\n",
      "\n",
      "   5. can he do that for you\n",
      "\n",
      "   6. \" friend \" is a broad category\n",
      "\n",
      "   7. in general , i usually let the client decide when this should occur , sometimes with some clients it will be a joint agreement , but even in that case it should weigh mostly on what the client feels\n",
      "\n",
      "   8. who takes care of your son , is a significant part of getting over your heartbreak\n",
      "\n",
      "   9. if everyone thinks you ' re worthless , then maybe you need to find new people to hang out with . seriously , the social context in which a person lives is a big influence in self - esteem . otherwise , you can go round and round trying to understand why you ' re not worthless , then go back to the same crowd and be knocked down again . there are many inspirational messages you can find in social media . maybe read some of the ones which state that no person is worthless , and that everyone has a good purpose to their life . also , since our culture is so saturated with the belief that if someone doesn ' t feel good about themselves that this is somehow terrible . bad feelings are part of living . they are the motivation to remove ourselves from situations and relationships which do us more harm than good . bad feelings do feel terrible . your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_single_example(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== First 5 Training Histories ===\n",
      "\n",
      "Example 1:\n",
      "can i change my feeling of being worthless to everyone ? i ' m going through some things with my feelings and myself . i barely sleep and i do nothing but think about how i ' m worthless and how i shouldn ' t be here . i ' ve never tried or contemplated suicide . i ' ve always wanted to fix my issues , but i never get around to it . how can i change my feeling of being worthless to everyone ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "can i change my feeling of being worthless to everyone ? i ' m going through some things with my feelings and myself . i barely sleep and i do nothing but think about how i ' m worthless and how i shouldn ' t be here . i ' ve never tried or contemplated suicide . i ' ve always wanted to fix my issues , but i never get around to it . how can i change my feeling of being worthless to everyone ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "can i change my feeling of being worthless to everyone ? i ' m going through some things with my feelings and myself . i barely sleep and i do nothing but think about how i ' m worthless and how i shouldn ' t be here . i ' ve never tried or contemplated suicide . i ' ve always wanted to fix my issues , but i never get around to it . how can i change my feeling of being worthless to everyone ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "can i change my feeling of being worthless to everyone ? i ' m going through some things with my feelings and myself . i barely sleep and i do nothing but think about how i ' m worthless and how i shouldn ' t be here . i ' ve never tried or contemplated suicide . i ' ve always wanted to fix my issues , but i never get around to it . how can i change my feeling of being worthless to everyone ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "can i change my feeling of being worthless to everyone ? i ' m going through some things with my feelings and myself . i barely sleep and i do nothing but think about how i ' m worthless and how i shouldn ' t be here . i ' ve never tried or contemplated suicide . i ' ve always wanted to fix my issues , but i never get around to it . how can i change my feeling of being worthless to everyone ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_histories(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from openai==0.28) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from openai==0.28) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (1.12.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/ninackjeong/miniconda3/envs/ckj-speech/lib/python3.8/site-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(file_path: str) -> str:\n",
    "    \"\"\"Load OpenAI API key from a file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounselingResponseGenerator:\n",
    "    def __init__(self, api_key_path: str):\n",
    "        \"\"\"Initialize the generator with path to API key file.\"\"\"\n",
    "        api_key = self.load_api_key(api_key_path)\n",
    "        openai.api_key = api_key\n",
    "        self.rules = {\n",
    "            \"pronouns\": {\n",
    "                \"name\": \"Personal Pronouns Rule\",\n",
    "                \"accepted\": \"Use personal pronouns, including inclusive 'we'\",\n",
    "                \"rejected\": \"Avoid using any personal pronouns\"\n",
    "            },\n",
    "            \"voice\": {\n",
    "                \"name\": \"Voice Rule\",\n",
    "                \"accepted\": \"Use active voice\",\n",
    "                \"rejected\": \"Use passive voice\"\n",
    "            },\n",
    "            \"tense\": {\n",
    "                \"name\": \"Tense Rule\",\n",
    "                \"accepted\": \"Use present tense\",\n",
    "                \"rejected\": \"Use past tense\"  \n",
    "            },\n",
    "            \"mood\": {\n",
    "                \"name\": \"Mood Rule\",\n",
    "                \"accepted\": \"Use polite imperative mood\",\n",
    "                \"rejected\": \"Use imperative mood\" # changed from \"Avoid imperative mood\" to this\n",
    "            },\n",
    "            \"emotional\": {\n",
    "                \"name\": \"Emotional Words Rule\",\n",
    "                \"accepted\": \"Use emotional words and cognitive verbs (like feel, understand, think, believe)\",\n",
    "                \"rejected\": \"Avoid using any emotional words or cognitive verbs\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def load_api_key(self, api_key_path: str) -> str:\n",
    "        \"\"\"Load API key from file.\"\"\"\n",
    "        with open(api_key_path, 'r') as f:\n",
    "            return f.read().strip()\n",
    "\n",
    "    def load_questions(self, file_path: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Load questions from counsel chat JSON file and remove duplicates.\n",
    "        Returns a list of unique questions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Remove duplicates\n",
    "        unique_questions = set()\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "            # Process train data\n",
    "            for item in data['train']:\n",
    "                for utterance in item['utterances']:\n",
    "                    if utterance['history']:\n",
    "                        unique_questions.add(utterance['history'][0])\n",
    "            \n",
    "            # Process valid data\n",
    "            for item in data['valid']:\n",
    "                for utterance in item['utterances']:\n",
    "                    if utterance['history']:\n",
    "                        unique_questions.add(utterance['history'][0])\n",
    "        \n",
    "        # Convert set back to list\n",
    "        questions = list(unique_questions)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"\\nQuestion Statistics:\")\n",
    "        print(f\"Total unique questions: {len(questions)}\")\n",
    "        \n",
    "        # Optional: Print a few example questions\n",
    "        print(\"\\nExample questions:\")\n",
    "        for q in questions[:3]:\n",
    "            print(f\"- {q[:100]}...\")\n",
    "            \n",
    "        return questions\n",
    "\n",
    "    def generate_prompt(self, question: str, rule_key: str, is_accepted: bool) -> str:\n",
    "        \"\"\"Generate a prompt that emphasizes maintaining the same meaning.\"\"\"\n",
    "        rule = self.rules[rule_key]\n",
    "        style = \"accepted\" if is_accepted else \"rejected\"\n",
    "        \n",
    "        prompt = f\"\"\"As a counseling assistant, provide a response to the following question.\n",
    "\n",
    "        Your response must follow these requirements:\n",
    "        1. MOST IMPORTANT: The content and therapeutic meaning of your response must be clear and complete\n",
    "        2. Linguistic Style Rule: {rule[style]}\n",
    "        \n",
    "        Critical Instructions:\n",
    "        - Your response should convey EXACTLY THE SAME therapeutic information and meaning\n",
    "        - ONLY the linguistic style should change, not the underlying meaning or counseling content\n",
    "        - Keep the response concise and limited to a single sentence\n",
    "        - Focus on providing supportive counseling while maintaining the required linguistic style\n",
    "        \n",
    "        Question: {question}\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "    def get_gpt4_response(self, prompt: str) -> str:\n",
    "        \"\"\"Get response from GPT-4.\"\"\"\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"You are a counseling assistant specializing in providing supportive and therapeutic responses. Your task is to provide empathetic and helpful responses while following specific linguistic style requirements. The meaning and therapeutic content must remain consistent regardless of the linguistic style used.\"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            return response['choices'][0]['message']['content'].strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting GPT-4 response: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def generate_dataset(self, questions: List[str], rule_key: str) -> pd.DataFrame:\n",
    "        \"\"\"Generate pairs of responses for a specific rule.\"\"\"\n",
    "        data = []\n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"Processing question {i}/{len(questions)} for {self.rules[rule_key]['name']}\")\n",
    "            accepted, rejected = self.generate_response_pair(question, rule_key)\n",
    "            data.append({\n",
    "                'question': question,\n",
    "                'accepted_response': accepted,\n",
    "                'rejected_response': rejected,\n",
    "                'rule': self.rules[rule_key]['name']\n",
    "            })\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def generate_response_pair(self, question: str, rule_key: str) -> Tuple[str, str]:\n",
    "        \"\"\"Generate a pair of responses for a given question and rule.\"\"\"\n",
    "        accepted_prompt = self.generate_prompt(question, rule_key, True)\n",
    "        rejected_prompt = self.generate_prompt(question, rule_key, False)\n",
    "        \n",
    "        accepted_response = self.get_gpt4_response(accepted_prompt)\n",
    "        rejected_response = self.get_gpt4_response(rejected_prompt)\n",
    "        \n",
    "        return accepted_response, rejected_response\n",
    "\n",
    "    def process_all_rules(self, data_path: str, output_dir: str, sample_size: int = None):\n",
    "        \"\"\"Process all rules and save results to separate CSV files.\"\"\"\n",
    "        questions = self.load_questions(data_path)\n",
    "        print(f\"Loaded {len(questions)} unique questions\")\n",
    "\n",
    "        if sample_size:\n",
    "            if sample_size > len(questions):\n",
    "                print(f\"Warning: Requested sample size ({sample_size}) is larger than available unique questions ({len(questions)})\")\n",
    "                sample_size = len(questions)\n",
    "            questions = questions[:sample_size]\n",
    "            print(f\"Using sample of {sample_size} questions\")\n",
    "            \n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for rule_key in self.rules:\n",
    "            print(f\"\\nProcessing {self.rules[rule_key]['name']}...\")\n",
    "            df = self.generate_dataset(questions, rule_key)\n",
    "            output_path = output_dir / f'counseling_responses_{rule_key}.csv'\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = Path(\"/Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/scripts\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = CounselingResponseGenerator('api_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_key.txt              gpt-family.ipynb\n",
      "counsel-gpt-family.ipynb langchain_test.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question Statistics:\n",
      "Total unique questions: 785\n",
      "\n",
      "Example questions:\n",
      "- is my ex - boyfriend a pathological liar ? i have an ex - boyfriend who just lies about everything ....\n",
      "- how do i make new friends ? in the past year , two of my best and only close friends moved to differ...\n",
      "- is it appropriate to give my counselor a bottle of wine for christmas ? i am an international studen...\n",
      "Loaded 785 unique questions\n",
      "Using sample of 5 questions\n",
      "\n",
      "Processing Personal Pronouns Rule...\n",
      "Processing question 1/5 for Personal Pronouns Rule\n",
      "Processing question 2/5 for Personal Pronouns Rule\n",
      "Processing question 3/5 for Personal Pronouns Rule\n",
      "Processing question 4/5 for Personal Pronouns Rule\n",
      "Processing question 5/5 for Personal Pronouns Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/counsel-chat/GPT-4/test-phase1/counseling_responses_pronouns.csv\n",
      "\n",
      "Processing Voice Rule...\n",
      "Processing question 1/5 for Voice Rule\n",
      "Processing question 2/5 for Voice Rule\n",
      "Processing question 3/5 for Voice Rule\n",
      "Processing question 4/5 for Voice Rule\n",
      "Processing question 5/5 for Voice Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/counsel-chat/GPT-4/test-phase1/counseling_responses_voice.csv\n",
      "\n",
      "Processing Tense Rule...\n",
      "Processing question 1/5 for Tense Rule\n",
      "Processing question 2/5 for Tense Rule\n",
      "Processing question 3/5 for Tense Rule\n",
      "Processing question 4/5 for Tense Rule\n",
      "Processing question 5/5 for Tense Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/counsel-chat/GPT-4/test-phase1/counseling_responses_tense.csv\n",
      "\n",
      "Processing Mood Rule...\n",
      "Processing question 1/5 for Mood Rule\n",
      "Processing question 2/5 for Mood Rule\n",
      "Processing question 3/5 for Mood Rule\n",
      "Processing question 4/5 for Mood Rule\n",
      "Processing question 5/5 for Mood Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/counsel-chat/GPT-4/test-phase1/counseling_responses_mood.csv\n",
      "\n",
      "Processing Emotional Words Rule...\n",
      "Processing question 1/5 for Emotional Words Rule\n",
      "Processing question 2/5 for Emotional Words Rule\n",
      "Processing question 3/5 for Emotional Words Rule\n",
      "Processing question 4/5 for Emotional Words Rule\n",
      "Processing question 5/5 for Emotional Words Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/counsel-chat/GPT-4/test-phase1/counseling_responses_emotional.csv\n"
     ]
    }
   ],
   "source": [
    "generator.process_all_rules(\n",
    "    data_path = HOME_DIR / 'public-data' / 'counsel-chat' / 'counsel_chat_250-tokens_full.json',\n",
    "    output_dir = HOME_DIR / 'generated-data' / 'counsel-chat' / 'GPT-4' / 'test-phase1',\n",
    "    sample_size = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InstructGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalResponseGenerator:\n",
    "    def __init__(self, api_key_path: str):\n",
    "        \"\"\"Initialize the generator with path to API key file.\"\"\"\n",
    "        api_key = load_api_key(api_key_path)\n",
    "        openai.api_key = api_key\n",
    "        self.rules = {\n",
    "            \"pronouns\": {\n",
    "                \"name\": \"Personal Pronouns Rule\",\n",
    "                \"accepted\": \"Use personal pronouns, including inclusive 'we'\",\n",
    "                \"rejected\": \"Avoid using any personal pronouns\"\n",
    "            },\n",
    "            \"voice\": {\n",
    "                \"name\": \"Voice Rule\",\n",
    "                \"accepted\": \"Use active voice\",\n",
    "                \"rejected\": \"Use passive voice\"\n",
    "            },\n",
    "            \"tense\": {\n",
    "                \"name\": \"Tense Rule\",\n",
    "                \"accepted\": \"Use present tense\",\n",
    "                \"rejected\": \"Use past tense\"\n",
    "            },\n",
    "            \"mood\": {\n",
    "                \"name\": \"Mood Rule\",\n",
    "                \"accepted\": \"Use polite imperative mood\",\n",
    "                \"rejected\": \"Avoid using imperative mood\"\n",
    "            },\n",
    "            \"emotional\": {\n",
    "                \"name\": \"Emotional Words Rule\",\n",
    "                \"accepted\": \"Use emotional words and cognitive verbs (like feel, understand, think, believe)\",\n",
    "                \"rejected\": \"Avoid using any emotional words or cognitive verbs\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def generate_prompt(self, question: str, rule_key: str, is_accepted: bool) -> str:\n",
    "        \"\"\"Generate a prompt that emphasizes maintaining the same meaning.\"\"\"\n",
    "        rule = self.rules[rule_key]\n",
    "        style = \"accepted\" if is_accepted else \"rejected\"\n",
    "        \n",
    "        prompt = f\"\"\"You are a legal assistant specializing in Australian law cases. Your task is to provide legally accurate responses while following specific linguistic style requirements. The meaning and legal content must remain consistent regardless of the linguistic style used.\n",
    "\n",
    "As a legal assistant, provide a response to the following legal question.\n",
    "\n",
    "Your response must follow these requirements:\n",
    "1. MOST IMPORTANT: The factual content and legal meaning of your response must be clear and complete\n",
    "2. Linguistic Style Rule: {rule[style]}\n",
    "\n",
    "Critical Instructions:\n",
    "- Your response should convey EXACTLY THE SAME legal information and meaning as you would normally provide\n",
    "- ONLY the linguistic style should change, not the underlying meaning or legal content\n",
    "- Keep the response concise and limited to a single sentence\n",
    "- Focus on answering the legal question while maintaining the required linguistic style\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "    def get_instruct_response(self, prompt: str) -> str:\n",
    "            \"\"\"Get response using gpt-3.5-turbo.\"\"\"\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=150\n",
    "                )\n",
    "                return response.choices[0].message['content'].strip()\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting GPT response: {e}\")\n",
    "                return \"\"\n",
    "\n",
    "    def load_questions(self, file_path: str) -> List[str]:\n",
    "        \"\"\"Load questions from JSONL file.\"\"\"\n",
    "        questions = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                questions.append(data['question'])\n",
    "        return questions\n",
    "\n",
    "    def generate_dataset(self, questions: List[str], rule_key: str) -> pd.DataFrame:\n",
    "        \"\"\"Generate pairs of responses for a specific rule.\"\"\"\n",
    "        data = []\n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"Processing question {i}/{len(questions)} for {self.rules[rule_key]['name']}\")\n",
    "            accepted, rejected = self.generate_response_pair(question, rule_key)\n",
    "            data.append({\n",
    "                'question': question,\n",
    "                'accepted_response': accepted,\n",
    "                'rejected_response': rejected,\n",
    "                'rule': self.rules[rule_key]['name']\n",
    "            })\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def generate_response_pair(self, question: str, rule_key: str) -> Tuple[str, str]:\n",
    "        \"\"\"Generate a pair of responses for a given question and rule.\"\"\"\n",
    "        accepted_prompt = self.generate_prompt(question, rule_key, True)\n",
    "        rejected_prompt = self.generate_prompt(question, rule_key, False)\n",
    "        \n",
    "        accepted_response = self.get_instruct_response(accepted_prompt)\n",
    "        rejected_response = self.get_instruct_response(rejected_prompt)\n",
    "        \n",
    "        return accepted_response, rejected_response\n",
    "\n",
    "    def process_all_rules(self, data_path: str, output_dir: str, sample_size: int = None):\n",
    "        \"\"\"Process all rules and save results to separate CSV files.\"\"\"\n",
    "        questions = self.load_questions(data_path)\n",
    "        \n",
    "        if sample_size:\n",
    "            questions = questions[:sample_size]\n",
    "            \n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for rule_key in self.rules:\n",
    "            print(f\"\\nProcessing {self.rules[rule_key]['name']}...\")\n",
    "            df = self.generate_dataset(questions, rule_key)\n",
    "            output_path = output_dir / f'responses_{rule_key}.csv'\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_gpt_generator = LegalResponseGenerator('api_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Personal Pronouns Rule...\n",
      "Processing question 1/20 for Personal Pronouns Rule\n",
      "Processing question 2/20 for Personal Pronouns Rule\n",
      "Processing question 3/20 for Personal Pronouns Rule\n",
      "Processing question 4/20 for Personal Pronouns Rule\n",
      "Processing question 5/20 for Personal Pronouns Rule\n",
      "Processing question 6/20 for Personal Pronouns Rule\n",
      "Processing question 7/20 for Personal Pronouns Rule\n",
      "Processing question 8/20 for Personal Pronouns Rule\n",
      "Processing question 9/20 for Personal Pronouns Rule\n",
      "Processing question 10/20 for Personal Pronouns Rule\n",
      "Processing question 11/20 for Personal Pronouns Rule\n",
      "Processing question 12/20 for Personal Pronouns Rule\n",
      "Processing question 13/20 for Personal Pronouns Rule\n",
      "Processing question 14/20 for Personal Pronouns Rule\n",
      "Processing question 15/20 for Personal Pronouns Rule\n",
      "Processing question 16/20 for Personal Pronouns Rule\n",
      "Processing question 17/20 for Personal Pronouns Rule\n",
      "Processing question 18/20 for Personal Pronouns Rule\n",
      "Processing question 19/20 for Personal Pronouns Rule\n",
      "Processing question 20/20 for Personal Pronouns Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test-phase1/responses_pronouns.csv\n",
      "\n",
      "Processing Voice Rule...\n",
      "Processing question 1/20 for Voice Rule\n",
      "Processing question 2/20 for Voice Rule\n",
      "Processing question 3/20 for Voice Rule\n",
      "Processing question 4/20 for Voice Rule\n",
      "Processing question 5/20 for Voice Rule\n",
      "Processing question 6/20 for Voice Rule\n",
      "Processing question 7/20 for Voice Rule\n",
      "Processing question 8/20 for Voice Rule\n",
      "Processing question 9/20 for Voice Rule\n",
      "Processing question 10/20 for Voice Rule\n",
      "Processing question 11/20 for Voice Rule\n",
      "Processing question 12/20 for Voice Rule\n",
      "Processing question 13/20 for Voice Rule\n",
      "Processing question 14/20 for Voice Rule\n",
      "Processing question 15/20 for Voice Rule\n",
      "Processing question 16/20 for Voice Rule\n",
      "Processing question 17/20 for Voice Rule\n",
      "Processing question 18/20 for Voice Rule\n",
      "Processing question 19/20 for Voice Rule\n",
      "Processing question 20/20 for Voice Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test-phase1/responses_voice.csv\n",
      "\n",
      "Processing Tense Rule...\n",
      "Processing question 1/20 for Tense Rule\n",
      "Processing question 2/20 for Tense Rule\n",
      "Processing question 3/20 for Tense Rule\n",
      "Processing question 4/20 for Tense Rule\n",
      "Processing question 5/20 for Tense Rule\n",
      "Processing question 6/20 for Tense Rule\n",
      "Processing question 7/20 for Tense Rule\n",
      "Processing question 8/20 for Tense Rule\n",
      "Processing question 9/20 for Tense Rule\n",
      "Processing question 10/20 for Tense Rule\n",
      "Processing question 11/20 for Tense Rule\n",
      "Processing question 12/20 for Tense Rule\n",
      "Processing question 13/20 for Tense Rule\n",
      "Processing question 14/20 for Tense Rule\n",
      "Processing question 15/20 for Tense Rule\n",
      "Processing question 16/20 for Tense Rule\n",
      "Processing question 17/20 for Tense Rule\n",
      "Processing question 18/20 for Tense Rule\n",
      "Processing question 19/20 for Tense Rule\n",
      "Processing question 20/20 for Tense Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test-phase1/responses_tense.csv\n",
      "\n",
      "Processing Mood Rule...\n",
      "Processing question 1/20 for Mood Rule\n",
      "Processing question 2/20 for Mood Rule\n",
      "Processing question 3/20 for Mood Rule\n",
      "Processing question 4/20 for Mood Rule\n",
      "Processing question 5/20 for Mood Rule\n",
      "Processing question 6/20 for Mood Rule\n",
      "Processing question 7/20 for Mood Rule\n",
      "Processing question 8/20 for Mood Rule\n",
      "Processing question 9/20 for Mood Rule\n",
      "Processing question 10/20 for Mood Rule\n",
      "Processing question 11/20 for Mood Rule\n",
      "Processing question 12/20 for Mood Rule\n",
      "Processing question 13/20 for Mood Rule\n",
      "Processing question 14/20 for Mood Rule\n",
      "Processing question 15/20 for Mood Rule\n",
      "Processing question 16/20 for Mood Rule\n",
      "Processing question 17/20 for Mood Rule\n",
      "Processing question 18/20 for Mood Rule\n",
      "Processing question 19/20 for Mood Rule\n",
      "Processing question 20/20 for Mood Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test-phase1/responses_mood.csv\n",
      "\n",
      "Processing Emotional Words Rule...\n",
      "Processing question 1/20 for Emotional Words Rule\n",
      "Processing question 2/20 for Emotional Words Rule\n",
      "Processing question 3/20 for Emotional Words Rule\n",
      "Processing question 4/20 for Emotional Words Rule\n",
      "Processing question 5/20 for Emotional Words Rule\n",
      "Processing question 6/20 for Emotional Words Rule\n",
      "Processing question 7/20 for Emotional Words Rule\n",
      "Processing question 8/20 for Emotional Words Rule\n",
      "Processing question 9/20 for Emotional Words Rule\n",
      "Processing question 10/20 for Emotional Words Rule\n",
      "Processing question 11/20 for Emotional Words Rule\n",
      "Processing question 12/20 for Emotional Words Rule\n",
      "Processing question 13/20 for Emotional Words Rule\n",
      "Processing question 14/20 for Emotional Words Rule\n",
      "Processing question 15/20 for Emotional Words Rule\n",
      "Processing question 16/20 for Emotional Words Rule\n",
      "Processing question 17/20 for Emotional Words Rule\n",
      "Processing question 18/20 for Emotional Words Rule\n",
      "Processing question 19/20 for Emotional Words Rule\n",
      "Processing question 20/20 for Emotional Words Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/InstructGPT/test-phase1/responses_emotional.csv\n"
     ]
    }
   ],
   "source": [
    "instruct_gpt_generator.process_all_rules(\n",
    "    data_path = HOME_DIR / 'public-data' / 'open-australian-legal-qa' / 'qa.jsonl',\n",
    "    output_dir = HOME_DIR / 'generated-data' / 'open-australian-legal-qa' / 'InstructGPT' / 'test-phase1',\n",
    "    sample_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalResponseGenerator:\n",
    "    def __init__(self, api_key_path: str):\n",
    "        \"\"\"Initialize the generator with path to API key file.\"\"\"\n",
    "        api_key = load_api_key(api_key_path)\n",
    "        openai.api_key = api_key\n",
    "        self.rules = {\n",
    "            \"pronouns\": {\n",
    "                \"name\": \"Personal Pronouns Rule\",\n",
    "                \"accepted\": \"Use personal pronouns, including inclusive 'we'\",\n",
    "                \"rejected\": \"Avoid using any personal pronouns\"\n",
    "            },\n",
    "            \"voice\": {\n",
    "                \"name\": \"Voice Rule\",\n",
    "                \"accepted\": \"Use active voice\",\n",
    "                \"rejected\": \"Use passive voice\"\n",
    "            },\n",
    "            \"tense\": {\n",
    "                \"name\": \"Tense Rule\",\n",
    "                \"accepted\": \"Use present tense\",\n",
    "                \"rejected\": \"Use past tense\"\n",
    "            },\n",
    "            \"mood\": {\n",
    "                \"name\": \"Mood Rule\",\n",
    "                \"accepted\": \"Use polite imperative mood\",\n",
    "                \"rejected\": \"Avoid using imperative mood\"\n",
    "            },\n",
    "            \"emotional\": {\n",
    "                \"name\": \"Emotional Words Rule\",\n",
    "                \"accepted\": \"Use emotional words and cognitive verbs (like feel, understand, think, believe)\",\n",
    "                \"rejected\": \"Avoid using any emotional words or cognitive verbs\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def generate_prompt(self, question: str, rule_key: str, is_accepted: bool) -> str:\n",
    "        \"\"\"Generate a prompt that emphasizes maintaining the same meaning.\"\"\"\n",
    "        rule = self.rules[rule_key]\n",
    "        style = \"accepted\" if is_accepted else \"rejected\"\n",
    "        \n",
    "        prompt = f\"\"\"As a legal assistant, provide a response to the following legal question.\n",
    "\n",
    "        Your response must follow these requirements:\n",
    "        1. MOST IMPORTANT: The factual content and legal meaning of your response must be clear and complete\n",
    "        2. Linguistic Style Rule: {rule[style]}\n",
    "        \n",
    "        Critical Instructions:\n",
    "        - Your response should convey EXACTLY THE SAME legal information and meaning as you would normally provide\n",
    "        - ONLY the linguistic style should change, not the underlying meaning or legal content\n",
    "        - Keep the response concise and limited to a single sentence\n",
    "        - Focus on answering the legal question while maintaining the required linguistic style\n",
    "        \n",
    "        Question: {question}\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "    def get_gpt4_response(self, prompt: str) -> str:\n",
    "            \"\"\"Get response from latest GPT-4.\"\"\"\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4-0125-preview\",\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\", \n",
    "                            \"content\": \"You are a legal assistant specializing in Australian law cases. Your task is to provide legally accurate responses while following specific linguistic style requirements. The meaning and legal content must remain consistent regardless of the linguistic style used.\"\n",
    "                        },\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=150\n",
    "                )\n",
    "                return response.choices[0].message['content'].strip()\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting GPT-4 response: {e}\")\n",
    "                return \"\"\n",
    "\n",
    "    def load_questions(self, file_path: str) -> List[str]:\n",
    "        \"\"\"Load questions from JSONL file.\"\"\"\n",
    "        questions = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                questions.append(data['question'])\n",
    "        return questions\n",
    "\n",
    "    def generate_dataset(self, questions: List[str], rule_key: str) -> pd.DataFrame:\n",
    "        \"\"\"Generate pairs of responses for a specific rule.\"\"\"\n",
    "        data = []\n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"Processing question {i}/{len(questions)} for {self.rules[rule_key]['name']}\")\n",
    "            accepted, rejected = self.generate_response_pair(question, rule_key)\n",
    "            data.append({\n",
    "                'question': question,\n",
    "                'accepted_response': accepted,\n",
    "                'rejected_response': rejected,\n",
    "                'rule': self.rules[rule_key]['name']\n",
    "            })\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def generate_response_pair(self, question: str, rule_key: str) -> Tuple[str, str]:\n",
    "        \"\"\"Generate a pair of responses for a given question and rule.\"\"\"\n",
    "        accepted_prompt = self.generate_prompt(question, rule_key, True)\n",
    "        rejected_prompt = self.generate_prompt(question, rule_key, False)\n",
    "        \n",
    "        accepted_response = self.get_gpt4_response(accepted_prompt)\n",
    "        rejected_response = self.get_gpt4_response(rejected_prompt)\n",
    "        \n",
    "        return accepted_response, rejected_response\n",
    "\n",
    "    def process_all_rules(self, data_path: str, output_dir: str, sample_size: int = None):\n",
    "        \"\"\"Process all rules and save results to separate CSV files.\"\"\"\n",
    "        questions = self.load_questions(data_path)\n",
    "        \n",
    "        if sample_size:\n",
    "            questions = questions[:sample_size]\n",
    "            \n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for rule_key in self.rules:\n",
    "            print(f\"\\nProcessing {self.rules[rule_key]['name']}...\")\n",
    "            df = self.generate_dataset(questions, rule_key)\n",
    "            output_path = output_dir / f'responses_{rule_key}.csv'\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_generator = LegalResponseGenerator('api_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Personal Pronouns Rule...\n",
      "Processing question 1/20 for Personal Pronouns Rule\n",
      "Processing question 2/20 for Personal Pronouns Rule\n",
      "Processing question 3/20 for Personal Pronouns Rule\n",
      "Processing question 4/20 for Personal Pronouns Rule\n",
      "Processing question 5/20 for Personal Pronouns Rule\n",
      "Processing question 6/20 for Personal Pronouns Rule\n",
      "Processing question 7/20 for Personal Pronouns Rule\n",
      "Processing question 8/20 for Personal Pronouns Rule\n",
      "Processing question 9/20 for Personal Pronouns Rule\n",
      "Processing question 10/20 for Personal Pronouns Rule\n",
      "Processing question 11/20 for Personal Pronouns Rule\n",
      "Processing question 12/20 for Personal Pronouns Rule\n",
      "Processing question 13/20 for Personal Pronouns Rule\n",
      "Processing question 14/20 for Personal Pronouns Rule\n",
      "Processing question 15/20 for Personal Pronouns Rule\n",
      "Processing question 16/20 for Personal Pronouns Rule\n",
      "Processing question 17/20 for Personal Pronouns Rule\n",
      "Processing question 18/20 for Personal Pronouns Rule\n",
      "Processing question 19/20 for Personal Pronouns Rule\n",
      "Processing question 20/20 for Personal Pronouns Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test-phase1/responses_pronouns.csv\n",
      "\n",
      "Processing Voice Rule...\n",
      "Processing question 1/20 for Voice Rule\n",
      "Processing question 2/20 for Voice Rule\n",
      "Processing question 3/20 for Voice Rule\n",
      "Processing question 4/20 for Voice Rule\n",
      "Processing question 5/20 for Voice Rule\n",
      "Processing question 6/20 for Voice Rule\n",
      "Processing question 7/20 for Voice Rule\n",
      "Processing question 8/20 for Voice Rule\n",
      "Processing question 9/20 for Voice Rule\n",
      "Processing question 10/20 for Voice Rule\n",
      "Processing question 11/20 for Voice Rule\n",
      "Processing question 12/20 for Voice Rule\n",
      "Processing question 13/20 for Voice Rule\n",
      "Processing question 14/20 for Voice Rule\n",
      "Processing question 15/20 for Voice Rule\n",
      "Processing question 16/20 for Voice Rule\n",
      "Processing question 17/20 for Voice Rule\n",
      "Processing question 18/20 for Voice Rule\n",
      "Processing question 19/20 for Voice Rule\n",
      "Processing question 20/20 for Voice Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test-phase1/responses_voice.csv\n",
      "\n",
      "Processing Tense Rule...\n",
      "Processing question 1/20 for Tense Rule\n",
      "Processing question 2/20 for Tense Rule\n",
      "Processing question 3/20 for Tense Rule\n",
      "Processing question 4/20 for Tense Rule\n",
      "Processing question 5/20 for Tense Rule\n",
      "Processing question 6/20 for Tense Rule\n",
      "Processing question 7/20 for Tense Rule\n",
      "Processing question 8/20 for Tense Rule\n",
      "Processing question 9/20 for Tense Rule\n",
      "Processing question 10/20 for Tense Rule\n",
      "Processing question 11/20 for Tense Rule\n",
      "Processing question 12/20 for Tense Rule\n",
      "Processing question 13/20 for Tense Rule\n",
      "Processing question 14/20 for Tense Rule\n",
      "Processing question 15/20 for Tense Rule\n",
      "Processing question 16/20 for Tense Rule\n",
      "Processing question 17/20 for Tense Rule\n",
      "Processing question 18/20 for Tense Rule\n",
      "Processing question 19/20 for Tense Rule\n",
      "Processing question 20/20 for Tense Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test-phase1/responses_tense.csv\n",
      "\n",
      "Processing Mood Rule...\n",
      "Processing question 1/20 for Mood Rule\n",
      "Processing question 2/20 for Mood Rule\n",
      "Processing question 3/20 for Mood Rule\n",
      "Processing question 4/20 for Mood Rule\n",
      "Processing question 5/20 for Mood Rule\n",
      "Processing question 6/20 for Mood Rule\n",
      "Processing question 7/20 for Mood Rule\n",
      "Processing question 8/20 for Mood Rule\n",
      "Processing question 9/20 for Mood Rule\n",
      "Processing question 10/20 for Mood Rule\n",
      "Processing question 11/20 for Mood Rule\n",
      "Processing question 12/20 for Mood Rule\n",
      "Processing question 13/20 for Mood Rule\n",
      "Processing question 14/20 for Mood Rule\n",
      "Processing question 15/20 for Mood Rule\n",
      "Processing question 16/20 for Mood Rule\n",
      "Processing question 17/20 for Mood Rule\n",
      "Processing question 18/20 for Mood Rule\n",
      "Processing question 19/20 for Mood Rule\n",
      "Processing question 20/20 for Mood Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test-phase1/responses_mood.csv\n",
      "\n",
      "Processing Emotional Words Rule...\n",
      "Processing question 1/20 for Emotional Words Rule\n",
      "Processing question 2/20 for Emotional Words Rule\n",
      "Processing question 3/20 for Emotional Words Rule\n",
      "Processing question 4/20 for Emotional Words Rule\n",
      "Processing question 5/20 for Emotional Words Rule\n",
      "Processing question 6/20 for Emotional Words Rule\n",
      "Processing question 7/20 for Emotional Words Rule\n",
      "Processing question 8/20 for Emotional Words Rule\n",
      "Processing question 9/20 for Emotional Words Rule\n",
      "Processing question 10/20 for Emotional Words Rule\n",
      "Processing question 11/20 for Emotional Words Rule\n",
      "Processing question 12/20 for Emotional Words Rule\n",
      "Processing question 13/20 for Emotional Words Rule\n",
      "Processing question 14/20 for Emotional Words Rule\n",
      "Processing question 15/20 for Emotional Words Rule\n",
      "Processing question 16/20 for Emotional Words Rule\n",
      "Processing question 17/20 for Emotional Words Rule\n",
      "Processing question 18/20 for Emotional Words Rule\n",
      "Processing question 19/20 for Emotional Words Rule\n",
      "Processing question 20/20 for Emotional Words Rule\n",
      "Saved to /Volumes/ssd/01-ckj-postdoc/LLM-alignment-data-generation/generated-data/open-australian-legal-qa/GPT-4o/test-phase1/responses_emotional.csv\n"
     ]
    }
   ],
   "source": [
    "gpt4o_generator.process_all_rules(\n",
    "    data_path = HOME_DIR / 'public-data' / 'open-australian-legal-qa' / 'qa.jsonl',\n",
    "    output_dir = HOME_DIR / 'generated-data' / 'open-australian-legal-qa' / 'GPT-4o' / 'test-phase1',\n",
    "    sample_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Uploading Generated Data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(tokenizer, dataset_name, input_min_text_length=2, input_max_text_length=8):\n",
    "    EOS_TOKEN = tokenizer.eos_token\n",
    "    train_dataset = load_dataset(dataset_name)\n",
    "    num_proc = 4\n",
    "\n",
    "    # Accepted Prompt (with rules)\n",
    "    system_input_with_rules = generate_accepted_prompt()\n",
    "\n",
    "    # Rejected Prompt (rules negated)\n",
    "    system_input_without_rules = generate_rejected_prompt()\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        new_examples = {\n",
    "            \"accepted\": [],\n",
    "            \"rejected\": [],\n",
    "            \"accepted_input_ids\": [],\n",
    "            \"rejected_input_ids\": [],\n",
    "        }\n",
    "        for question in examples[\"question\"]:\n",
    "            # Accepted Version\n",
    "            accepted_prompt = f\"### System:\\n{system_input_with_rules}\\n### User:\\n{question}\\n### Assistant:\\n\"\n",
    "            accepted_query = accepted_prompt + EOS_TOKEN\n",
    "            tokenized_accepted = tokenizer(accepted_query, truncation=True)\n",
    "\n",
    "            # Rejected Version\n",
    "            rejected_prompt = f\"### System:\\n{system_input_without_rules}\\n### User:\\n{question}\\n### Assistant:\\n\"\n",
    "            rejected_query = rejected_prompt + EOS_TOKEN\n",
    "            tokenized_rejected = tokenizer(rejected_query, truncation=True)\n",
    "\n",
    "            # Add to dataset\n",
    "            new_examples[\"accepted\"].append(accepted_query)\n",
    "            new_examples[\"rejected\"].append(rejected_query)\n",
    "            new_examples[\"accepted_input_ids\"].append(tokenized_accepted[\"input_ids\"])\n",
    "            new_examples[\"rejected_input_ids\"].append(tokenized_rejected[\"input_ids\"])\n",
    "\n",
    "        return new_examples\n",
    "\n",
    "    # Apply preprocessing to dataset\n",
    "    ds = train_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        num_proc=num_proc,\n",
    "    )\n",
    "\n",
    "    # Filter for maximum length\n",
    "    ds = ds.filter(\n",
    "        lambda x: len(x[\"accepted_input_ids\"]) < 2048 and len(x[\"rejected_input_ids\"]) < 2048,\n",
    "        batched=False\n",
    "    )\n",
    "\n",
    "    # Set final dataset format\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(tokenizer, \"dataset_name\")\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "  return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(tokenizer, \"elsayedissa/alignment-questions\")\n",
    "dataset['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckj-speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
